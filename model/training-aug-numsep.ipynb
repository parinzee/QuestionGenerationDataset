{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbwjJF8nAHrn"
      },
      "source": [
        "# Welcome to Automatic Thai Question Generation from Context!\n",
        "This is notebook detailing how to finetune **mT5 for question-generation in the Thai language!** Specifically this notebook will train the **mT5-small-thai-e2e-qg-aug-numsep.**\n",
        "\n",
        "\n",
        "First, we will mount our google drive so our models don't get deleted (╯°□°)╯︵ ┻━┻ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ecgcLxQBIym",
        "outputId": "45246293-8b9a-43cf-8ab1-60a8eeeb18e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8Pj_wDYBKS4"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Install dependencies that we need in order to run/train our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy4QtOY3AHrq",
        "outputId": "054c2d23-0627-4b02-badc-6b984dcc40d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Collecting ijson\n",
            "  Downloading ijson-3.1.4-cp37-cp37m-manylinux2010_x86_64.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 33.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 63.9 MB/s \n",
            "\u001b[?25hCollecting lightning-bolts\n",
            "  Downloading lightning_bolts-0.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 56.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n",
            "\u001b[K     |████████████████████████████████| 585 kB 68.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Collecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 77.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.46.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 70.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, tokenizers, pytorch-lightning, huggingface-hub, transformers, sentencepiece, lightning-bolts, ijson\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.7.0 ijson-3.1.4 lightning-bolts-0.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 sentencepiece-0.1.96 tokenizers-0.12.1 torchmetrics-0.9.1 transformers-4.19.4 yarl-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pythainlp\n",
            "  Downloading pythainlp-3.0.8-py3-none-any.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 11.6 MB/s \n",
            "\u001b[?25hCollecting epitran\n",
            "  Downloading epitran-1.22-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting tinydb>=3.0\n",
            "  Downloading tinydb-4.7.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from pythainlp) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from tinydb>=3.0->pythainlp) (4.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from epitran) (57.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from epitran) (2022.6.2)\n",
            "Collecting panphon>=0.19\n",
            "  Downloading panphon-0.20.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 309 kB/s \n",
            "\u001b[?25hCollecting marisa-trie\n",
            "  Downloading marisa_trie-0.7.7-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 60.2 MB/s \n",
            "\u001b[?25hCollecting unicodecsv\n",
            "  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from panphon>=0.19->epitran) (6.0)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from panphon>=0.19->epitran) (0.5.3)\n",
            "Collecting munkres\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: numpy>=1.20.2 in /usr/local/lib/python3.7/dist-packages (from panphon>=0.19->epitran) (1.21.6)\n",
            "Building wheels for collected packages: unicodecsv\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10768 sha256=c5f41f0b39907a7b75095b809293995249749c290287bb299f7291e6cb56c1b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/f4/8a/a5024fb77b32ed369e5c409081e5f00fbe3b92fdad653f6e69\n",
            "Successfully built unicodecsv\n",
            "Installing collected packages: unicodecsv, munkres, tinydb, panphon, marisa-trie, pythainlp, epitran\n",
            "Successfully installed epitran-1.22 marisa-trie-0.7.7 munkres-1.1.4 panphon-0.20.0 pythainlp-3.0.8 tinydb-4.7.0 unicodecsv-0.14.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.18-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 28.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 64.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 67.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=ed676dc54402f683dbc181a0a420fbeb1d0b84ceef379998824d47371ee3f644\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.18\n"
          ]
        }
      ],
      "source": [
        "# Remove \"sample_data\" in colab\n",
        "!rm -rf sample_data\n",
        "# Solve some protobuf problems\n",
        "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='python'\n",
        "\n",
        "## Install dependencies\n",
        "%pip install torch ijson pandas torchmetrics lightning-bolts transformers sentencepiece protobuf beautifulsoup4 pytorch-lightning \n",
        "%pip install pythainlp epitran\n",
        "%pip install -U nltk\n",
        "%pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azBzzH6B8Qvs"
      },
      "source": [
        "And then login to wandb to keep track of our training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExDEcJdo8Qvt"
      },
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXaB7UrtCyNz"
      },
      "source": [
        "Then we will import all the things we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "thZlTjPEC2Hl"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import urllib.request\n",
        "import os\n",
        "import ijson\n",
        "import json\n",
        "import re\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import (\n",
        "    MT5ForConditionalGeneration,\n",
        "    MT5TokenizerFast,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1xgys6NAHrt"
      },
      "source": [
        "# Gather & Process datasets\n",
        "- xquad-thai\n",
        "- iapp-wiki-qa-dataset\n",
        "- thaiqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1zSGe8oW-nc",
        "outputId": "db875c3d-697b-4649-e36e-6d34020d4678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded xquad.json from https://github.com/deepmind/xquad/raw/master/xquad.th.json\n",
            "Downloaded iapp-thai-wikipedia-qa.json from https://raw.githubusercontent.com/iapp-technology/iapp-wiki-qa-dataset/main/iapp-thai-wikipedia-qa-1961-docs-9170-questions.json\n",
            "Downloaded thaiqa.zip from https://github.com/PyThaiNLP/thaiqa_squad/raw/main/data.zip\n"
          ]
        }
      ],
      "source": [
        "def download_dataset(url, file_name):\n",
        "    urllib.request.urlretrieve(\n",
        "        url,\n",
        "        os.path.join(\"dataset/\", file_name),\n",
        "        reporthook=(\n",
        "            lambda count, block, total: print(\n",
        "                f\"Downloading {file_name}: {math.floor((count * block) / total * 100)}%\",\n",
        "                end=\"\\r\",\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    print(f\"Downloaded {file_name} from {url}\")\n",
        "\n",
        "\n",
        "# Check if the dataset already exists\n",
        "if not (\n",
        "    os.path.exists(\"dataset/xquad.json\")\n",
        "    and os.path.exists(\"dataset/iapp-thai-wikipedia-qa.json\")\n",
        "):\n",
        "    os.mkdir(\"dataset\")\n",
        "    # Download all datasets\n",
        "    download_dataset(\n",
        "        \"https://github.com/deepmind/xquad/raw/master/xquad.th.json\", \"xquad.json\"\n",
        "    )\n",
        "    download_dataset(\n",
        "        \"https://raw.githubusercontent.com/iapp-technology/iapp-wiki-qa-dataset/main/iapp-thai-wikipedia-qa-1961-docs-9170-questions.json\",\n",
        "        \"iapp-thai-wikipedia-qa.json\",\n",
        "    )\n",
        "    download_dataset(\n",
        "        \"https://github.com/PyThaiNLP/thaiqa_squad/raw/main/data.zip\", \"thaiqa.zip\"\n",
        "    )\n",
        "    with ZipFile(\"dataset/thaiqa.zip\") as zipfile:\n",
        "        os.mkdir(\"dataset/thaiqa\")\n",
        "        zipfile.extractall(\"dataset/thaiqa/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGr9y17tXChS"
      },
      "source": [
        "Before we load our data into memory, we need to augment data since our dataset is very small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QRDmouHqXfaN"
      },
      "outputs": [],
      "source": [
        "def augment_data_xquad(source_list, target_list, context, qas):\n",
        "    for amt_questions in range(1, len(qas) + 1):\n",
        "        source_text = f\"สร้าง {amt_questions} คำถาม: {context}\"\n",
        "        target_text = \"\"\n",
        "\n",
        "        for index, qa in enumerate(qas[:amt_questions]):\n",
        "            target_text += (\n",
        "                f\" <{index + 1}> {qa['question'].strip()} A: {qa['answers'][0]['text'].strip()}\"\n",
        "            )\n",
        "\n",
        "        source_list.append(source_text.strip())\n",
        "        target_list.append(target_text.strip())\n",
        "\n",
        "\n",
        "def augment_data_iapp(source_list, target_list, context, qas):\n",
        "    filtered_qas = list(filter(lambda x: len(x[\"a\"]) != 0 and len(x[\"q\"]) != 0, qas))\n",
        "    for amt_questions in range(1, len(filtered_qas) + 1):\n",
        "        source_text = f\"สร้าง {amt_questions} คำถาม: {context}\"\n",
        "        target_text = \"\"\n",
        "\n",
        "        for index, qa in enumerate(filtered_qas[:amt_questions]):\n",
        "            target_text += f\" <{index + 1}> {qa['q'].strip()} A: {qa['a'][0].strip()}\"\n",
        "\n",
        "        source_list.append(source_text.strip())\n",
        "        target_list.append(target_text.strip())\n",
        "\n",
        "\n",
        "def augment_data_thaiqa(source_list, target_list, context, qas):\n",
        "    for amt_questions in range(1, len(qas) + 1):\n",
        "        source_text = f\"สร้าง {amt_questions} คำถาม: {context}\"\n",
        "        target_text = \"\"\n",
        "\n",
        "        for index, qa in enumerate(list(qas.iterrows())[:amt_questions]):\n",
        "            target_text += f\" <{index + 1}> {qa[1]['question'].strip()} A: {qa[1]['answer'].strip()}\"\n",
        "\n",
        "        source_list.append(source_text.strip())\n",
        "        target_list.append(target_text.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "CkNR3MnNAHrt"
      },
      "outputs": [],
      "source": [
        "# This list will store all the Q&A\n",
        "source_list = []\n",
        "target_list = []\n",
        "\n",
        "# Start cleaning data\n",
        "squad = open(os.path.join(\"dataset/\", \"xquad.json\"))\n",
        "iapp = open(os.path.join(\"dataset/\", \"iapp-thai-wikipedia-qa.json\"))\n",
        "iapp_keys = open(os.path.join(\"dataset/\", \"iapp-thai-wikipedia-qa.json\"))\n",
        "thaiqa = open(os.path.join(\"dataset/thaiqa/data/train.jsonl\"))\n",
        "\n",
        "squad_json = ijson.items(squad, \"data.item\")\n",
        "iapp_json = json.load(iapp)\n",
        "iapp_keys = ijson.kvitems(iapp_keys, \"db\")\n",
        "thaiqa_df = pd.read_json(thaiqa, lines=True)\n",
        "\n",
        "# Get data from xquad\n",
        "for obj in squad_json:\n",
        "    paragraphs = obj[\"paragraphs\"]\n",
        "    for p in paragraphs:\n",
        "        context = p[\"context\"]\n",
        "        qas = [p for p in p[\"qas\"] if len(p) > 0]\n",
        "\n",
        "        augment_data_xquad(source_list, target_list, context, qas)\n",
        "\n",
        "# Get dataset from iapp\n",
        "for key in iapp_keys:\n",
        "    try:\n",
        "        obj = iapp_json[\"db\"][key[0]]\n",
        "        context = obj[\"detail\"]\n",
        "        qas = obj[\"QA\"]\n",
        "        target_text = \"\"\n",
        "\n",
        "        augment_data_iapp(source_list, target_list, context, qas)\n",
        "\n",
        "    except KeyError as e:\n",
        "        # Due to the dataset, there will always be a keyerror on \"detail\" which is the dataset's metadata\n",
        "        if str(e) != \"'detail'\":\n",
        "            print(f\"KeyError: {e}\")\n",
        "\n",
        "# Get data from thaiqa\n",
        "article_ids = set(thaiqa_df[\"article_id\"])\n",
        "for id in article_ids:\n",
        "    questions = thaiqa_df[thaiqa_df[\"article_id\"] == id]\n",
        "\n",
        "    # Remove html markup\n",
        "    soup = BeautifulSoup(questions[\"context\"].iloc[0])\n",
        "\n",
        "    # Remove parenthesis because some are empty\n",
        "    context = re.sub(r\"\\(\\)\", \"\", soup.text)\n",
        "\n",
        "    # Remove double spaces resulting from removing parenthesis\n",
        "    context = re.sub(r\"\\s\\s+\", \" \", context)\n",
        "\n",
        "    augment_data_thaiqa(source_list, target_list, context, questions)\n",
        "\n",
        "dataframe = pd.DataFrame({\"source_text\": source_list, \"target_text\": target_list})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw9omjA6Hngr"
      },
      "source": [
        "And then split our dataframe into train, valid, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-9XrtGfkHs7e"
      },
      "outputs": [],
      "source": [
        "index_train_split = math.floor(dataframe.shape[0] * 0.8)\n",
        "train_df, valid_test = (\n",
        "    dataframe.iloc[\n",
        "        :index_train_split,\n",
        "    ],\n",
        "    dataframe.iloc[\n",
        "        index_train_split:,\n",
        "    ],\n",
        ")\n",
        "\n",
        "index_test_split = math.floor(valid_test.shape[0] * 0.5)\n",
        "valid_df, test_df = (\n",
        "    valid_test.iloc[\n",
        "        :index_test_split,\n",
        "    ],\n",
        "    valid_test.iloc[\n",
        "        index_test_split:,\n",
        "    ],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VbYBMzdAHry"
      },
      "source": [
        "# Training\n",
        "Now we can finally get to the nitty-gritty and start defining our training loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atE8E0FNAHry",
        "outputId": "23aeeaf0-61c5-4632-9fa8-ee92d2230c4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 16\n"
          ]
        }
      ],
      "source": [
        "pl.seed_everything(16)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "class MT5Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.data = df.reset_index()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.source_max_len = 1024\n",
        "        self.target_max_len = 1024\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_row = self.data.iloc[idx]\n",
        "        source, target = data_row[\"source_text\"], data_row[\"target_text\"]\n",
        "\n",
        "        source_encoding = self.tokenizer(\n",
        "            source,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.source_max_len,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        target_encoding = self.tokenizer(\n",
        "            target,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.target_max_len,\n",
        "            truncation=True,\n",
        "            add_special_tokens=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # Ensure labels are correct (see huggingface T5 training documentation)\n",
        "        labels = target_encoding.input_ids\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return dict(\n",
        "            input_ids=source_encoding.input_ids.flatten(),\n",
        "            attention_mask=source_encoding.attention_mask.flatten(),\n",
        "            decoder_input_ids=labels.flatten(),\n",
        "            decoder_attention_mask=target_encoding.attention_mask.flatten(),\n",
        "        )\n",
        "\n",
        "\n",
        "class MT5DataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        train_df,\n",
        "        valid_df,\n",
        "        test_df,\n",
        "        batch_size: int = 1,\n",
        "        num_workers: int = 2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_df = train_df\n",
        "        self.valid_df = valid_df\n",
        "        self.test_df = test_df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None, batch_size=1):\n",
        "        self.batch_size = batch_size\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            self.train_data = MT5Dataset(self.train_df, self.tokenizer)\n",
        "            self.valid_data = MT5Dataset(self.valid_df, self.tokenizer)\n",
        "\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.test_data = MT5Dataset(self.test_df, self.tokenizer)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.train_data, batch_size=self.batch_size, shuffle=True\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.valid_data, batch_size=self.batch_size, shuffle=False\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.test_data, batch_size=self.batch_size, shuffle=False\n",
        "        )\n",
        "\n",
        "\n",
        "class MT5Lightning(pl.LightningModule):\n",
        "    def __init__(self, model, tokenizer):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.avg_training_loss = None\n",
        "        self.avg_val_loss = None\n",
        "\n",
        "    def forward(\n",
        "        self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask\n",
        "    ):\n",
        "        output = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "        )\n",
        "        return output.loss, output.logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        decoder_input_ids = batch[\"decoder_input_ids\"]\n",
        "        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
        "\n",
        "        output = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "        )\n",
        "\n",
        "        self.log(\"loss\", output[0], prog_bar=True, on_step=True, on_epoch=True)\n",
        "\n",
        "        return output[0]\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        decoder_input_ids = batch[\"decoder_input_ids\"]\n",
        "        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
        "\n",
        "        output = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "        )\n",
        "\n",
        "        self.log(\"val_loss\", output[0], prog_bar=True, on_step=True, on_epoch=True)\n",
        "\n",
        "        return output[0]\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        decoder_input_ids = batch[\"decoder_input_ids\"]\n",
        "        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
        "\n",
        "        output = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "        )\n",
        "\n",
        "        self.log(\"test_loss\", output.loss, prog_bar=True)\n",
        "\n",
        "        return output.loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=3e-4)\n",
        "\n",
        "    def training_epoch_end(self, training_step_outputs):\n",
        "        self.avg_training_loss = np.round(\n",
        "            torch.mean(torch.stack([x[\"loss\"] for x in training_step_outputs])).item(),\n",
        "            4,\n",
        "        )\n",
        "        path = \"\"\n",
        "        if os.path.exists(\"drive\"):\n",
        "            path += \"drive/MyDrive/mt5-thai-qg/\"\n",
        "        else:\n",
        "            path += \"outputs/\"\n",
        "        path += f\"mt5-qg-epoch-{self.current_epoch}-train-loss-{self.avg_training_loss}-val-loss-{self.avg_val_loss}\"\n",
        "        self.tokenizer.save_pretrained(path)\n",
        "        self.model.save_pretrained(path)\n",
        "\n",
        "    def validation_epoch_end(self, validation_step_outputs):\n",
        "        _loss = [x.cpu() for x in validation_step_outputs]\n",
        "        self.avg_val_loss = np.round(\n",
        "            torch.mean(torch.stack(_loss)).item(),\n",
        "            4,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47el2aZzWinO"
      },
      "source": [
        "## Actually Train\n",
        "Start actually training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445,
          "referenced_widgets": [
            "e2057f29fb524ddb8067319b5b7fe976",
            "e1f0483aada4478f913296c458682f57",
            "e23333bcdc344f5dbc025dc0b5d5720f",
            "25a352b7e3db4d94b98a313e504ee229",
            "4245cbec68954714a655813b2041d6ab",
            "86e44856bd5c4ca08e7f3d635264c94a",
            "205f85b08c574acf97aeff29ef5b9ac3",
            "1a86d75276544f108cdff7a975f6be11",
            "23a51164e52b44b2a668ba5ffb9cb3d1",
            "571c4e722c27492dab23b837fba4a5d5",
            "736451e8c85947e5bb6d57cabad09eea",
            "e8d3943d458a43e5a9c28a4c0e478704",
            "d070834d9db8489ea47cae4e06eb3141",
            "d7f6e3322e1f42a0840a4adcf7b01a1f",
            "613e53da433a4155b4d86f7aa9ef925d",
            "5379187705694e8d8b17e961cb3645be",
            "856c6c53a587463fa1731db511daa50f",
            "1f8f9567c8d44972817bfdcf86dd87ac",
            "ea0eb9be0329489b8e8b6e76afaf078a",
            "760a47d6bd81431c9560056c36bdb60e",
            "638fd5a8c37e4e3b97126222b7bfa39a",
            "3e19e1555a7a4abab5c25299205005e7"
          ]
        },
        "id": "_8JCn9TOXBkZ",
        "outputId": "45c50081-df6e-467c-def9-6fcb9d4b6823"
      },
      "outputs": [],
      "source": [
        "model = MT5ForConditionalGeneration.from_pretrained(\n",
        "    \"google/mt5-small\", return_dict=True\n",
        ")\n",
        "tokenizer = MT5TokenizerFast.from_pretrained(\"google/mt5-small\")\n",
        "dataset = MT5DataModule(tokenizer, train_df, valid_df, test_df, batch_size=1)\n",
        "\n",
        "MT5Model = MT5Lightning(model, tokenizer)\n",
        "\n",
        "callbacks = []\n",
        "callbacks.append(EarlyStopping(monitor=\"val_loss\", mode=\"min\"))\n",
        "\n",
        "wandb_logger = WandbLogger(\n",
        "    project=\"mT5-thai-multiple-e2e-qg\", name=\"mT5-small-thai-multiple-e2e-qg\"\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    logger=wandb_logger,\n",
        "    max_epochs=20,\n",
        "    log_every_n_steps=1,\n",
        "    callbacks=callbacks,\n",
        "    accumulate_grad_batches=20\n",
        ")\n",
        "\n",
        "trainer.fit(MT5Model, dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYHPsomEAHr1"
      },
      "source": [
        "# Testing & Inferencing\n",
        "Now we will load up our model and do some inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00J8W8Hze71C"
      },
      "source": [
        "## Inferencing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0LBea3SAHr2",
        "outputId": "ebc88be7-c7bf-4561-ddb8-5c5d9f3cd1c6"
      },
      "outputs": [],
      "source": [
        "model = MT5ForConditionalGeneration.from_pretrained(\n",
        "    \"drive/MyDrive/mt5-thai-qg/mt5-qg-epoch-5-train-loss-0.855-val-loss-0.9273\",\n",
        "    return_dict=True,\n",
        ")\n",
        "tokenizer = MT5TokenizerFast.from_pretrained(\n",
        "    \"drive/MyDrive/mt5-thai-qg/mt5-qg-epoch-5-train-loss-0.855-val-loss-0.9273\"\n",
        ")\n",
        "\n",
        "model.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_NX1m4b-itN-"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "    with torch.no_grad():\n",
        "        input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=True)\n",
        "\n",
        "        input_ids = input_ids.cuda()\n",
        "\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            num_beams=3,\n",
        "            max_length=10000,\n",
        "            repetition_penalty=2.5,\n",
        "            length_penalty=1.0,\n",
        "            early_stopping=True,\n",
        "            top_p=50,\n",
        "            top_k=20,\n",
        "            num_return_sequences=1,\n",
        "        )\n",
        "\n",
        "        preds = [\n",
        "            tokenizer.decode(\n",
        "                g,\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=True,\n",
        "            )\n",
        "            for g in generated_ids\n",
        "        ]\n",
        "    return preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs9gTmzde71D"
      },
      "source": [
        "Run this cell below to try out the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD7ZlxCLe71E",
        "outputId": "e8edfe03-82b3-43d3-91b6-380f2d15b7d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1. เฟซบุ๊ก เป็นบริการเครือข่ายสังคมสัญชาติอะไร A: อเมริกัน 2. เฟซบุ๊ก ก่อตั้งเมื่อไหร่ A: 4 กุมภาพันธ์ ค.ศ. 2004 3. เฟซบุ๊ก ก่อตั้งโดยใคร A: มาร์ก ซักเคอร์เบิร์ก 4. เฟซบุ๊ก สมาชิกเพื่อนผู้ก่อตั้งคือใคร A: มาร์ก ซักเคอร์เบิร์ก 5. เฟซบุ๊ก มีผู้ใช้ที่ยังคงใช้งานรายเดือนที่เท่าไร A: 28 พันล้านคน']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_to_predict = \"\"\"สร้าง 5 คำถาม: เฟซบุ๊ก (อังกฤษ: Facebook) เป็นบริการเครือข่ายสังคมสัญชาติอเมริกัน สำนักงานใหญ่อยู่ที่ เมนโลพาร์ก รัฐแคลิฟอร์เนีย เฟซบุ๊กก่อตั้งเมื่อวันพุธที่ 4 กุมภาพันธ์ ค.ศ. 2004 โดยมาร์ก ซักเคอร์เบิร์ก และเพื่อนร่วมห้องภายในมหาวิทยาลัย และเหล่าเพื่อนในมหาวิทยาลัยฮาร์วาร์ด พร้อมโดยสมาชิกเพื่อนผู้ก่อตั้ง Eduardo Saverin, Andrew McCollum, Dustin Moskovitz และ Chris Hughes ในท้ายที่สุดเว็บไซต์มีการเข้าชมอย่างจำกัด ทำให้เหล่านักศึกษาภายในมหาวิทยาลัยฮาร์วาร์ด แต่ภายหลังได้ขยายเพิ่มจำนวนในมหาวิทยาลัย ในพื้นที่บอสตัน ไอวีลีก และมหาวิทยาลัยสแตนฟอร์ด และค่อย ๆ รับรองมหาวิทยาลัยอื่นต่าง ๆ และต่อมาก็รับรองโรงเรียนมัธยมศึกษา โดยเฟซบุ๊กให้การอนุญาตให้เยาวชนอายุต่ำกว่า 13 ปีทั่วโลกสามารถสมัครสมาชิกได้ภายในเว็บไซต์ โดยไม่ต้องอ้างอิงหลักฐานใด ๆ ใน ค.ศ. 2020 เฟซบุ๊กอ้างว่ามีผู้ใช้ที่ยังคงใช้งานรายเดือนที่ 28 พันล้านคน โดยมีผู้ใช้งานทั่วโลกมากเป็นอันดับ 7 และเป็นแอปโทรศัพท์ที่มีคนโหลดมากที่สุดในคริสต์ทศวรรษ 2010\"\"\"\n",
        "predicted = predict(text_to_predict)\n",
        "predicted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYilwSaXe71F"
      },
      "source": [
        "## Evaluate Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ayStuz4e71F"
      },
      "source": [
        "Setup our dataset for testm mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ch5VFBFEjFHC"
      },
      "outputs": [],
      "source": [
        "dataset = MT5DataModule(tokenizer, train_df, valid_df, test_df, batch_size=4)\n",
        "dataset.setup(stage=\"test\")\n",
        "test_loader = dataset.test_dataloader()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcQobh-Ze71G"
      },
      "source": [
        "Define a preprocessing function so that our metrics don't die"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4nYE23SrxY1Z"
      },
      "outputs": [],
      "source": [
        "from pythainlp import word_tokenize\n",
        "\n",
        "\n",
        "def pre_process(texts):\n",
        "    final = []\n",
        "    for text in texts:\n",
        "        final.append(\" \".join(word_tokenize(text, keep_whitespace=False)))\n",
        "    return final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wffoj8Ee71I"
      },
      "source": [
        "Our evaluation will use the following metrics:\n",
        "* ROUGE\n",
        "* CHRF\n",
        "* GLEU\n",
        "* METEOR\n",
        "\n",
        "Begin the evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W46w_hzMekps",
        "outputId": "7316a08d-78ee-4c17-9eb6-203a4c2c689a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/text/chrf.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  total_n_grams[n] = tensor(sum(n_grams_counts[n].values()))\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/text/chrf.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  for n_gram in hyp_n_grams_counts[n]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------\n",
            "Meteor: 0.5771521957033449\n",
            "GLEU: 0.349622574503331\n",
            "BLEU: 0.3545001149177551\n",
            "CHRF: 0.4814225435256958\n",
            "ROUGE: {'rouge1_fmeasure': tensor(0.8742), 'rouge1_precision': tensor(0.9097), 'rouge1_recall': tensor(0.8698), 'rouge2_fmeasure': tensor(0.7027), 'rouge2_precision': tensor(0.7305), 'rouge2_recall': tensor(0.7088), 'rougeL_fmeasure': tensor(0.8554), 'rougeL_precision': tensor(0.8902), 'rougeL_recall': tensor(0.8513), 'rougeLsum_fmeasure': tensor(0.8706), 'rougeLsum_precision': tensor(0.9064), 'rougeLsum_recall': tensor(0.8660)}\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from torchmetrics.text.rouge import ROUGEScore\n",
        "from torchmetrics import CHRFScore, BLEUScore\n",
        "from nltk.translate import meteor_score, gleu_score\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "rouge = ROUGEScore()\n",
        "chrf = CHRFScore()\n",
        "bleu = BLEUScore(smooth=True, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "meteor_avg = 0\n",
        "gleu_avg = 0\n",
        "\n",
        "labels_collect = []\n",
        "preds_collect = []\n",
        "\n",
        "for batch in test_loader:\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=batch[\"input_ids\"].cuda(),\n",
        "        num_beams=2,\n",
        "        max_length=1024,\n",
        "        repetition_penalty=2.5,\n",
        "        length_penalty=1.0,\n",
        "        early_stopping=True,\n",
        "        top_p=50,\n",
        "        top_k=0.95,\n",
        "        num_return_sequences=1,\n",
        "    )\n",
        "\n",
        "    preds = [\n",
        "        tokenizer.decode(\n",
        "            g,\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=True,\n",
        "        )\n",
        "        for g in generated_ids\n",
        "    ]\n",
        "\n",
        "    batch[\"decoder_input_ids\"][\n",
        "        batch[\"decoder_input_ids\"] == -100\n",
        "    ] = tokenizer.pad_token_id\n",
        "\n",
        "    labels = [\n",
        "        tokenizer.decode(\n",
        "            g,\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=True,\n",
        "        )\n",
        "        for g in batch[\"decoder_input_ids\"]\n",
        "    ]\n",
        "\n",
        "    preds = pre_process(preds)\n",
        "    labels = pre_process(labels)\n",
        "\n",
        "    for p, l in zip(preds, labels):\n",
        "        meteor_avg += meteor_score.single_meteor_score(p.split(\" \"), l.split(\" \"))\n",
        "        gleu_avg += gleu_score.sentence_gleu([l.split(\" \")], p.split(\" \"))\n",
        "\n",
        "    bleu(preds, [labels])\n",
        "    chrf(preds, [labels])\n",
        "    rouge(preds, labels)\n",
        "    preds_collect.append(preds)\n",
        "    labels_collect.append(labels)\n",
        "\n",
        "print(\"------\")\n",
        "print(f\"Meteor: {meteor_avg / (len(test_loader))}\")\n",
        "print(f\"GLEU: {gleu_avg / (len(test_loader))}\")\n",
        "print(f\"BLEU: {bleu.compute().item()}\")\n",
        "print(f\"CHRF: {chrf.compute().item()}\")\n",
        "print(f\"ROUGE: {rouge.compute()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3eZkafpe71J"
      },
      "source": [
        "# Misc\n",
        "Below are some other useful chunks of code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMVz2qmLe71K"
      },
      "source": [
        "## Export prediction & labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4iOPRt-v-tad"
      },
      "outputs": [],
      "source": [
        "label_final = [i for x in labels_collect for i in x]\n",
        "pred_final = [i for x in preds_collect for i in x]\n",
        "\n",
        "\n",
        "export = pd.DataFrame(\n",
        "    data=zip(label_final, pred_final), columns=[\"Labels\", \"Predictions\"]\n",
        ")\n",
        "export.to_json(\"output_finetuned_trained.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJhICYtQe71L"
      },
      "source": [
        "## Zip up Outputs\n",
        "Zip up the outputs & logs folder (with the models) to prepare them for exporting using zstd.\n",
        "\n",
        "### Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K8XyRk4e71L"
      },
      "outputs": [],
      "source": [
        "!apt install tar zstd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVktmw5le71L"
      },
      "source": [
        "### Zipping up everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1S0A_Cke71M"
      },
      "outputs": [],
      "source": [
        "!tar -c -I \"zstd -19 -T0\" -f \"mt5-thai-qg.tar.zst\" outputs/ lightning_logs/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mT5_train_thai (7).ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "599dbc988367df75f394341c14191e4f45ca195597a9b0aa004fda5844c2c20f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a86d75276544f108cdff7a975f6be11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8f9567c8d44972817bfdcf86dd87ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "205f85b08c574acf97aeff29ef5b9ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23a51164e52b44b2a668ba5ffb9cb3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25a352b7e3db4d94b98a313e504ee229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_571c4e722c27492dab23b837fba4a5d5",
            "placeholder": "​",
            "style": "IPY_MODEL_736451e8c85947e5bb6d57cabad09eea",
            "value": " 553/553 [00:00&lt;00:00, 4.90kB/s]"
          }
        },
        "3e19e1555a7a4abab5c25299205005e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4245cbec68954714a655813b2041d6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5379187705694e8d8b17e961cb3645be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571c4e722c27492dab23b837fba4a5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "613e53da433a4155b4d86f7aa9ef925d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638fd5a8c37e4e3b97126222b7bfa39a",
            "placeholder": "​",
            "style": "IPY_MODEL_3e19e1555a7a4abab5c25299205005e7",
            "value": " 357M/1.12G [03:13&lt;00:13, 60.1MB/s]"
          }
        },
        "638fd5a8c37e4e3b97126222b7bfa39a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "736451e8c85947e5bb6d57cabad09eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "760a47d6bd81431c9560056c36bdb60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "856c6c53a587463fa1731db511daa50f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e44856bd5c4ca08e7f3d635264c94a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d070834d9db8489ea47cae4e06eb3141": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856c6c53a587463fa1731db511daa50f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f8f9567c8d44972817bfdcf86dd87ac",
            "value": "Downloading:  31%"
          }
        },
        "d7f6e3322e1f42a0840a4adcf7b01a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0eb9be0329489b8e8b6e76afaf078a",
            "max": 1200794589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_760a47d6bd81431c9560056c36bdb60e",
            "value": 374494208
          }
        },
        "e1f0483aada4478f913296c458682f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e44856bd5c4ca08e7f3d635264c94a",
            "placeholder": "​",
            "style": "IPY_MODEL_205f85b08c574acf97aeff29ef5b9ac3",
            "value": "Downloading: 100%"
          }
        },
        "e2057f29fb524ddb8067319b5b7fe976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1f0483aada4478f913296c458682f57",
              "IPY_MODEL_e23333bcdc344f5dbc025dc0b5d5720f",
              "IPY_MODEL_25a352b7e3db4d94b98a313e504ee229"
            ],
            "layout": "IPY_MODEL_4245cbec68954714a655813b2041d6ab"
          }
        },
        "e23333bcdc344f5dbc025dc0b5d5720f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a86d75276544f108cdff7a975f6be11",
            "max": 553,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23a51164e52b44b2a668ba5ffb9cb3d1",
            "value": 553
          }
        },
        "e8d3943d458a43e5a9c28a4c0e478704": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d070834d9db8489ea47cae4e06eb3141",
              "IPY_MODEL_d7f6e3322e1f42a0840a4adcf7b01a1f",
              "IPY_MODEL_613e53da433a4155b4d86f7aa9ef925d"
            ],
            "layout": "IPY_MODEL_5379187705694e8d8b17e961cb3645be"
          }
        },
        "ea0eb9be0329489b8e8b6e76afaf078a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
