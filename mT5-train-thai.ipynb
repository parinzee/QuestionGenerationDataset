{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbwjJF8nAHrn"
      },
      "source": [
        "# Welcome to mt5-thai-QG\n",
        "This is notebook detailing how to finetune **mt5 for question-generation in the Thai language** \n",
        "\n",
        "\n",
        "First, we will mount our google drive so our models don't get deleted (╯°□°)╯︵ ┻━┻ \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_ecgcLxQBIym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dfbd3b-604f-46d8-9415-518beb5ebbfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Now we will install some requirements"
      ],
      "metadata": {
        "id": "i8Pj_wDYBKS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Oy4QtOY3AHrq",
        "outputId": "193dbbbd-3557-489f-be88-48bc222399ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ijson\n",
            "  Downloading ijson-3.1.4-cp37-cp37m-manylinux2010_x86_64.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.0-py3-none-any.whl (418 kB)\n",
            "\u001b[K     |████████████████████████████████| 418 kB 59.4 MB/s \n",
            "\u001b[?25hCollecting lightning-bolts\n",
            "  Downloading lightning_bolts-0.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 56.8 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 60.4 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n",
            "\u001b[K     |████████████████████████████████| 585 kB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 71.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Collecting PyYAML>=5.4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 65.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.46.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, tokenizers, pytorch-lightning, huggingface-hub, transformers, sentencepiece, lightning-bolts, ijson\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.7.0 ijson-3.1.4 lightning-bolts-0.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.4 sentencepiece-0.1.96 tokenizers-0.12.1 torchmetrics-0.9.0 transformers-4.19.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "# Remove \"sample_data\" in colab\n",
        "!rm -rf sample_data\n",
        "# Solve some protobuf problems\n",
        "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='python'\n",
        "# Install programs\n",
        "\n",
        "## Install ONNX\n",
        "#%pip install torch-ort onnxruntime-training -f https://download.onnxruntime.ai/onnxruntime_stable_cu111.html\n",
        "#!apt install ninja-build\n",
        "#!python -m torch_ort.configure\n",
        "\n",
        "## Install other stuff\n",
        "%pip install ijson pandas torchmetrics lightning-bolts transformers sentencepiece protobuf beautifulsoup4 pytorch-lightning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we will import all the things we need"
      ],
      "metadata": {
        "id": "bXaB7UrtCyNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import urllib.request\n",
        "import os\n",
        "import ijson\n",
        "import json\n",
        "import re\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "#from pl_bolts.callbacks import ORTCallback\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import (\n",
        "    MT5ForConditionalGeneration,\n",
        "    MT5TokenizerFast,\n",
        ")\n"
      ],
      "metadata": {
        "id": "thZlTjPEC2Hl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1xgys6NAHrt"
      },
      "source": [
        "# Gather & Process datasets\n",
        "- xquad-thai\n",
        "- iapp-wiki-qa-dataset\n",
        "- thaiqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CkNR3MnNAHrt",
        "outputId": "845ad929-17da-4234-e02a-db3147c2c2ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded xquad.json from https://github.com/deepmind/xquad/raw/master/xquad.th.json\n",
            "Downloaded iapp-thai-wikipedia-qa.json from https://raw.githubusercontent.com/iapp-technology/iapp-wiki-qa-dataset/main/iapp-thai-wikipedia-qa-1961-docs-9170-questions.json\n",
            "Downloaded thaiqa.zip from https://github.com/PyThaiNLP/thaiqa_squad/raw/main/data.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            source_text  \\\n",
              "0     สร้าง 14 คำถาม: ﻿ทีมรับของแพนเธอร์สถอดใจที่คะแ...   \n",
              "1     สร้าง 16 คำถาม: ทีมบรอนคอส เอาชนะทีม พิตต์สเบิ...   \n",
              "2     สร้าง 17 คำถาม: เพย์ตัน แมนนิง กลายเป็นควอเตอร...   \n",
              "3     สร้าง 12 คำถาม: เลดีกากา ซึ่งชนะรางวัลแกรมมี ห...   \n",
              "4     สร้าง 15 คำถาม: ขณะที่เหลือเวลาอีก 4:51 นาทีแค...   \n",
              "...                                                 ...   \n",
              "4485  สร้าง 2 คำถาม: ปกเกล้า อนันต์ สิบตำรวจตรี ปกเก...   \n",
              "4486  สร้าง 2 คำถาม: ธนาคารกสิกรไทย ธนาคารกสิกรไทย จ...   \n",
              "4487  สร้าง 2 คำถาม: ดิเรกสิน รัตนสิน พันโท ดิเรกสิน...   \n",
              "4488  สร้าง 2 คำถาม: วรพล ทองคำชู วรพล ทองคำชู นักเท...   \n",
              "4489  สร้าง 2 คำถาม: แอนนา ฟาริส แอนนา เคย์ ฟาริส (;...   \n",
              "\n",
              "                                            target_text  \n",
              "0     1. ทีมรับของแพนเธอร์สยอมแพ้ที่คะแนนเท่าไร A: 3...  \n",
              "1     1. ใครพ่ายแพ้ให้แก่ทีมบรอนคอสในรอบดิวิชั่น A: ...  \n",
              "2     1. เพย์ตัน แมนนิง อายุเท่าไรตอนที่เขาเล่นในซูเ...  \n",
              "3     1. เลดีกากา ชนะแกรมมีกี่รางวัล A: หก 2. เลดีกา...  \n",
              "4     1. แคโรไลนาเริ่มเล่นที่เส้นหลาที่เท่าไรเมื่อมี...  \n",
              "...                                                 ...  \n",
              "4485  1. ในปี 2560 ปกเกล้า อนันต์ เล่นในตำแหน่งกองกล...  \n",
              "4486  1. ธนาคารกสิกรไทยเป็นธนาคารในประเทศไทย มีสำนัก...  \n",
              "4487  1. พันโท ดิเรกสิน รัตนสิน เกิดเมื่อวันที่เท่าไ...  \n",
              "4488  1. นักเทนนิสชายไทย วรพล ทองคำชู ได้เหรียญทองจา...  \n",
              "4489  1. ในปี 2008 แอนนา เคย์ ฟาริสได้แสดงภาพยนตร์เร...  \n",
              "\n",
              "[4490 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a77b3d57-bd83-47e5-b196-4b13eeacafe6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>สร้าง 14 คำถาม: ﻿ทีมรับของแพนเธอร์สถอดใจที่คะแ...</td>\n",
              "      <td>1. ทีมรับของแพนเธอร์สยอมแพ้ที่คะแนนเท่าไร A: 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>สร้าง 16 คำถาม: ทีมบรอนคอส เอาชนะทีม พิตต์สเบิ...</td>\n",
              "      <td>1. ใครพ่ายแพ้ให้แก่ทีมบรอนคอสในรอบดิวิชั่น A: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>สร้าง 17 คำถาม: เพย์ตัน แมนนิง กลายเป็นควอเตอร...</td>\n",
              "      <td>1. เพย์ตัน แมนนิง อายุเท่าไรตอนที่เขาเล่นในซูเ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>สร้าง 12 คำถาม: เลดีกากา ซึ่งชนะรางวัลแกรมมี ห...</td>\n",
              "      <td>1. เลดีกากา ชนะแกรมมีกี่รางวัล A: หก 2. เลดีกา...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>สร้าง 15 คำถาม: ขณะที่เหลือเวลาอีก 4:51 นาทีแค...</td>\n",
              "      <td>1. แคโรไลนาเริ่มเล่นที่เส้นหลาที่เท่าไรเมื่อมี...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4485</th>\n",
              "      <td>สร้าง 2 คำถาม: ปกเกล้า อนันต์ สิบตำรวจตรี ปกเก...</td>\n",
              "      <td>1. ในปี 2560 ปกเกล้า อนันต์ เล่นในตำแหน่งกองกล...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4486</th>\n",
              "      <td>สร้าง 2 คำถาม: ธนาคารกสิกรไทย ธนาคารกสิกรไทย จ...</td>\n",
              "      <td>1. ธนาคารกสิกรไทยเป็นธนาคารในประเทศไทย มีสำนัก...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4487</th>\n",
              "      <td>สร้าง 2 คำถาม: ดิเรกสิน รัตนสิน พันโท ดิเรกสิน...</td>\n",
              "      <td>1. พันโท ดิเรกสิน รัตนสิน เกิดเมื่อวันที่เท่าไ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4488</th>\n",
              "      <td>สร้าง 2 คำถาม: วรพล ทองคำชู วรพล ทองคำชู นักเท...</td>\n",
              "      <td>1. นักเทนนิสชายไทย วรพล ทองคำชู ได้เหรียญทองจา...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4489</th>\n",
              "      <td>สร้าง 2 คำถาม: แอนนา ฟาริส แอนนา เคย์ ฟาริส (;...</td>\n",
              "      <td>1. ในปี 2008 แอนนา เคย์ ฟาริสได้แสดงภาพยนตร์เร...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4490 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a77b3d57-bd83-47e5-b196-4b13eeacafe6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a77b3d57-bd83-47e5-b196-4b13eeacafe6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a77b3d57-bd83-47e5-b196-4b13eeacafe6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "def download_dataset(url, file_name):\n",
        "    urllib.request.urlretrieve(\n",
        "        url,\n",
        "        os.path.join(\"dataset/\", file_name),\n",
        "        reporthook=(\n",
        "            lambda count, block, total: print(\n",
        "                f\"Downloading {file_name}: {math.floor((count * block) / total * 100)}%\",\n",
        "                end=\"\\r\",\n",
        "            )\n",
        "        ),\n",
        "    )\n",
        "    print(f\"Downloaded {file_name} from {url}\")\n",
        "\n",
        "\n",
        "# Check if the dataset already exists\n",
        "if not (os.path.exists(\"dataset/xquad.json\") and os.path.exists(\"dataset/iapp-thai-wikipedia-qa.json\")):\n",
        "    os.mkdir(\"dataset\")\n",
        "    # Download all datasets\n",
        "    download_dataset(\"https://github.com/deepmind/xquad/raw/master/xquad.th.json\", \"xquad.json\")\n",
        "    download_dataset(\"https://raw.githubusercontent.com/iapp-technology/iapp-wiki-qa-dataset/main/iapp-thai-wikipedia-qa-1961-docs-9170-questions.json\", \"iapp-thai-wikipedia-qa.json\")\n",
        "    download_dataset(\"https://github.com/PyThaiNLP/thaiqa_squad/raw/main/data.zip\", \"thaiqa.zip\")\n",
        "    with ZipFile(\"dataset/thaiqa.zip\") as zipfile:\n",
        "        os.mkdir(\"dataset/thaiqa\")\n",
        "        zipfile.extractall(\"dataset/thaiqa/\")\n",
        "\n",
        "# This list will store all the Q&A\n",
        "source_list = []\n",
        "target_list = []\n",
        "\n",
        "# Start cleaning data\n",
        "squad = open(os.path.join(\"dataset/\", \"xquad.json\"))\n",
        "iapp = open(os.path.join(\"dataset/\", \"iapp-thai-wikipedia-qa.json\"))\n",
        "iapp_keys = open(os.path.join(\"dataset/\", \"iapp-thai-wikipedia-qa.json\"))\n",
        "thaiqa = open(os.path.join(\"dataset/thaiqa/data/train.jsonl\"))\n",
        "\n",
        "squad_json = ijson.items(squad, \"data.item\")\n",
        "iapp_json = json.load(iapp)\n",
        "iapp_keys = ijson.kvitems(iapp_keys, \"db\")\n",
        "thaiqa_df = pd.read_json(thaiqa, lines=True)\n",
        "\n",
        "# Get data from xquad\n",
        "for obj in squad_json:\n",
        "    paragraphs = obj[\"paragraphs\"]\n",
        "    for p in paragraphs:\n",
        "        context = p[\"context\"]\n",
        "        qas = [p for p in p[\"qas\"] if len(p) > 0]\n",
        "\n",
        "        source_text = f\"สร้าง {len(qas)} คำถาม: {context}\"\n",
        "        target_text = \"\"\n",
        "\n",
        "        for number, qa in enumerate(qas):\n",
        "            target_text += (\n",
        "                f\"{number + 1}. {qa['question']} A: {qa['answers'][0]['text']} \"\n",
        "            )\n",
        "\n",
        "        source_list.append(source_text.strip())\n",
        "        target_list.append(target_text.strip())\n",
        "\n",
        "# Get dataset from iapp\n",
        "for key in iapp_keys:\n",
        "    try:\n",
        "        obj = iapp_json[\"db\"][key[0]] \n",
        "        context = obj[\"detail\"]\n",
        "        qas = obj[\"QA\"]\n",
        "        target_text = \"\"\n",
        "\n",
        "        qa_amount = 0\n",
        "\n",
        "        for number, qa in enumerate(qas):\n",
        "            if len(qa[\"a\"]) != 0 and len(qa[\"q\"]) != 0:\n",
        "                target_text += (\n",
        "                    f\"{number + 1}. {qa['q']} A: {qa['a'][0]} \"\n",
        "                )\n",
        "                qa_amount += 1\n",
        "\n",
        "        source_text = f\"สร้าง {qa_amount} คำถาม: {context}\"\n",
        "        source_list.append(source_text.strip())\n",
        "        target_list.append(target_text.strip())\n",
        "    \n",
        "    except KeyError as e:\n",
        "      # Due to the dataset, there will always be a keyerror on \"detail\" which is the dataset's metadata\n",
        "      if str(e) != \"'detail'\":\n",
        "        print(f\"KeyError: {e}\")\n",
        "    \n",
        "# Get data from thaiqa\n",
        "article_ids = set(thaiqa_df[\"article_id\"])\n",
        "for id in article_ids:\n",
        "    questions = thaiqa_df[thaiqa_df[\"article_id\"] == id]\n",
        "\n",
        "    # Remove html markup\n",
        "    soup = BeautifulSoup(questions[\"context\"].iloc[0])\n",
        "\n",
        "    # Remove parenthesis because some are empty\n",
        "    context = re.sub(r'\\(\\)', '', soup.text)\n",
        "\n",
        "    # Remove double spaces resulting from removing parenthesis\n",
        "    context = re.sub(r'\\s\\s+', \" \", context)\n",
        "\n",
        "    source_text = f\"สร้าง {len(questions)} คำถาม: {context}\"\n",
        "    target_text = \"\"\n",
        "\n",
        "    qa_number = 1\n",
        "    for _, question in questions.iterrows():\n",
        "        target_text += f\"{qa_number}. {question['question']} A: {question['answer']} \"\n",
        "        qa_number += 1\n",
        "    \n",
        "    source_list.append(source_text.strip())\n",
        "    target_list.append(target_text.strip())\n",
        "\n",
        "dataframe = pd.DataFrame({\"source_text\": source_list, \"target_text\": target_list})\n",
        "dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then split our dataframe into train, valid, and test sets."
      ],
      "metadata": {
        "id": "yw9omjA6Hngr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_train_split = math.floor(dataframe.shape[0] * 0.8)\n",
        "train_df, valid_test = dataframe.iloc[:index_train_split,], dataframe.iloc[index_train_split:,]\n",
        "\n",
        "index_test_split = math.floor(valid_test.shape[0] * 0.5)\n",
        "valid_df, test_df = valid_test.iloc[:index_test_split,], valid_test.iloc[index_test_split:,]"
      ],
      "metadata": {
        "id": "-9XrtGfkHs7e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VbYBMzdAHry"
      },
      "source": [
        "## Training\n",
        "Now we can finally get to the nitty-gritty and start defining our training loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "atE8E0FNAHry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8f9074-cc7b-4a0c-a08c-fe6899f1c829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 16\n"
          ]
        }
      ],
      "source": [
        "pl.seed_everything(16)\n",
        "torch.cuda.empty_cache()\n",
        "model_name = \"google/mt5-small\"\n",
        "\n",
        "class MT5Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, df, tokenizer):\n",
        "    self.data = df\n",
        "    self.tokenizer = tokenizer\n",
        "    self.source_max_len = 1024\n",
        "    self.target_max_len = 1024\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    data_row = self.data.iloc[idx]\n",
        "    source, target = data_row[\"source_text\"], data_row[\"target_text\"]\n",
        "\n",
        "    source_encoding = self.tokenizer(source,\n",
        "                              padding=\"max_length\",\n",
        "                              max_length=self.source_max_len,\n",
        "                              truncation=True, \n",
        "                              add_special_tokens=True,\n",
        "                              return_attention_mask=True,\n",
        "                              return_tensors=\"pt\")\n",
        "    \n",
        "    target_encoding = self.tokenizer(target,\n",
        "                            padding=\"max_length\",\n",
        "                            max_length=self.target_max_len,\n",
        "                            truncation=True,\n",
        "                            add_special_tokens=True,\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors=\"pt\")\n",
        "    \n",
        "    # Ensure labels are correct (see huggingface T5 training documentation)\n",
        "    labels = target_encoding.input_ids\n",
        "    labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "    return dict(\n",
        "        input_ids = source_encoding.input_ids.flatten(),\n",
        "        attention_mask = source_encoding.attention_mask.flatten(),\n",
        "        decoder_input_ids = labels.flatten(),\n",
        "        decoder_attention_mask = target_encoding.attention_mask.flatten()\n",
        "    )\n",
        "    \n",
        "\n",
        "\n",
        "class MT5DataModule(pl.LightningDataModule):\n",
        "  def __init__(self, tokenizer, train_df, valid_df, test_df, batch_size: int = 1, num_workers: int = 2):\n",
        "    super().__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.train_df = train_df\n",
        "    self.valid_df = valid_df\n",
        "    self.test_df = test_df\n",
        "    self.tokenizer = tokenizer\n",
        "  \n",
        "  def setup(self, stage: Optional[str] = None):\n",
        "    if stage == \"fit\" or stage is None:\n",
        "      self.train_data = MT5Dataset(self.train_df, self.tokenizer)\n",
        "      self.valid_df = MT5Dataset(self.valid_df, self.tokenizer)\n",
        "    \n",
        "    if stage == \"test\" or stage is None:\n",
        "      self.test_data = MT5Dataset(self.test_df, self.tokenizer)\n",
        "    \n",
        "  def train_dataloader(self):\n",
        "    return torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
        "  \n",
        "  def val_dataloader(self):\n",
        "    return torch.utils.data.DataLoader(self.valid_df, batch_size=self.batch_size, shuffle=False)\n",
        "  \n",
        "  def test_dataloader(self):\n",
        "    return torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class MT5Lightning(pl.LightningModule):\n",
        "  def __init__(self, model, tokenizer):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.avg_training_loss = None\n",
        "    self.avg_val_loss = None\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask):\n",
        "    output = self.model(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        labels=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask\n",
        "        )\n",
        "    return output.loss, output.logits\n",
        "  \n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    decoder_input_ids = batch[\"decoder_input_ids\"]\n",
        "    decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
        "\n",
        "    output = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask\n",
        "    )\n",
        "\n",
        "    self.log(\n",
        "         \"loss\", output[0], prog_bar=True, on_step=True, on_epoch=True\n",
        "    )\n",
        "\n",
        "    return output[0]\n",
        "  \n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    decoder_input_ids = batch[\"decoder_input_ids\"]\n",
        "    decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
        "    \n",
        "    output = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask\n",
        "    )\n",
        "\n",
        "\n",
        "    self.log(\n",
        "        \"val_loss\", output[0], prog_bar=True, on_step=True, on_epoch=True\n",
        "    )\n",
        "\n",
        "    return output[0]\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"input_ids\"]\n",
        "    attention_mask = batch[\"attention_mask\"]\n",
        "    decoder_input_ids = batch[\"decoder_input_ids\"]\n",
        "    decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
        "    \n",
        "    output = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask\n",
        "    )\n",
        "\n",
        "    self.log(\n",
        "        \"test_loss\", output.loss, prog_bar=True\n",
        "    )\n",
        "\n",
        "    return output.loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return torch.optim.AdamW(self.parameters(), lr=3e-4)\n",
        "  \n",
        "  def training_epoch_end(self, training_step_outputs):\n",
        "        self.avg_training_loss = np.round(\n",
        "            torch.mean(torch.stack([x[\"loss\"] for x in training_step_outputs])).item(),\n",
        "            4,\n",
        "        )\n",
        "        path = \"\"\n",
        "        if os.path.exists(\"drive\"):\n",
        "            path += \"drive/MyDrive/mt5-thai-qg/\"\n",
        "        else:\n",
        "            path += \"outputs/\"\n",
        "        path += f\"mt5-qg-epoch-{self.current_epoch}-train-loss-{self.avg_training_loss}-val-loss-{self.avg_val_loss}\"\n",
        "        self.tokenizer.save_pretrained(path)\n",
        "        self.model.save_pretrained(path)\n",
        "\n",
        "  def validation_epoch_end(self, validation_step_outputs):\n",
        "    _loss = [x.cpu() for x in validation_step_outputs]\n",
        "    self.avg_val_loss = np.round(\n",
        "         torch.mean(torch.stack(_loss)).item(),\n",
        "        4,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start actually training"
      ],
      "metadata": {
        "id": "47el2aZzWinO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MT5ForConditionalGeneration.from_pretrained(\"drive/MyDrive/mt5-thai-qg/mt5-qg-epoch-4-train-loss-0.961-val-loss-0.9701\", return_dict=True)\n",
        "tokenizer = MT5TokenizerFast.from_pretrained(\"drive/MyDrive/mt5-thai-qg/mt5-qg-epoch-4-train-loss-0.961-val-loss-0.9701\")\n",
        "dataset = MT5DataModule(\n",
        "    tokenizer,\n",
        "    train_df,\n",
        "    valid_df,\n",
        "    test_df,\n",
        ") \n",
        "\n",
        "MT5Model = MT5Lightning(model, tokenizer)\n",
        "\n",
        "callbacks=[]\n",
        "callbacks.append(EarlyStopping(monitor=\"val_loss\", mode=\"min\"))\n",
        "#callbacks.append(ORTCallback())\n",
        "\n",
        "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, logger=True, max_epochs=20, log_every_n_steps=1, callbacks=callbacks, profiler=\"simple\")\n",
        "trainer.fit(MT5Model, dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "a577f4a8a07a45229cb9837d6c0c6bcb",
            "c43fddadbd6a4e4dafcb5fcd1bd471d4",
            "bd393ef962614479b8b02e9e1b0ad19b",
            "1ce7ffc6310d4954ab722dbb9108041a",
            "0369f86bbbd444209bf0956213a98e6d",
            "bead2402c09c482bbd483d857700ed65",
            "a52eb124976e4faba7d5fb11983fea74",
            "2c5641d3422b43288f6c4799e7748e2e",
            "31a460e7eb0f4e1095e61ef2afc0f321",
            "7497e6bf01664ea79d5586eaa73daad6",
            "af47413154ea47aa8f2af208b4cf6121",
            "d544e76a3fbc4e71a007139298c55f6d",
            "f1b5cc8a67d64cd783a2c9fa11227dc8",
            "c8ac69fca6914b1f8eb0ca9556dc9fc5",
            "7fd3493ebd1747b29c2492371925e20b",
            "24a7dc38b673438bb13e471c7d162323",
            "71caa6aabab14199a6f0949ad571644b",
            "992e7cc84c274c84ae643ee9e7bbe58b",
            "5114330ee6544202ac54a67c672d4d7f",
            "600886ca0c2248cdaa9f4d44b7dbd612",
            "9a38c7f18bfe4c299c3ab9a5b8c3a818",
            "5475c31a35ba4481a85de75aecc7ee35"
          ]
        },
        "id": "_8JCn9TOXBkZ",
        "outputId": "14cd81e3-e249-4062-bee4-44b5ce03aeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /content/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                        | Params\n",
            "------------------------------------------------------\n",
            "0 | model | MT5ForConditionalGeneration | 300 M \n",
            "------------------------------------------------------\n",
            "300 M     Trainable params\n",
            "0         Non-trainable params\n",
            "300 M     Total params\n",
            "1,200.707 Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a577f4a8a07a45229cb9837d6c0c6bcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
            "                not been set for this class (_ResultMetric). The property determines if `update` by\n",
            "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
            "                achieved and we recommend setting this to `False`.\n",
            "                We provide an checking function\n",
            "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
            "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
            "                default for now) or if `full_state_update=False` can be used safely.\n",
            "                \n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d544e76a3fbc4e71a007139298c55f6d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r lightning_logs drive/MyDrive/mt5-thai-qg/"
      ],
      "metadata": {
        "id": "NZ7qhUYi8PFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYHPsomEAHr1"
      },
      "source": [
        "# Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0LBea3SAHr2"
      },
      "outputs": [],
      "source": [
        "#model = MT5ForConditionalGeneration.from_pretrained(\"drive/MyDrive/mt5-thai-qg/mt5-qg-epoch-4-train-loss-0.961-val-loss-0.9701\", return_dict=True)\n",
        "#tokenizer = MT5TokenizerFast.from_pretrained(\"drive/MyDrive/mt5-thai-qg/mt5-qg-epoch-4-train-loss-0.961-val-loss-0.9701\")\n",
        "\n",
        "text_to_predict =\"\"\"สร้าง 3 คำถาม: ดันเจียนซีจ (อังกฤษ: Dungeon Siege) เป็นเกมแอ็กชันเล่นตามบทบาทที่พัฒนาโดยแก๊สเพาเวิร์ดเกมส์ ซึ่งไมโครซอฟท์ได้จัดจำหน่ายบนแพลตฟอร์มไมโครซอฟท์ วินโดวส์ ในเดือนเมษายน ค.ศ. 2002 และเดสทิเนียร์ได้จัดจำหน่ายบนแพลตฟอร์มแมคโอเอสเท็นในปีถัดไป โดยมีฉากอยู่ในอาณาจักรยุคกลางสมมติ ชื่อ เอห์บ เกมนี้ยังจัดเป็นแนวแฟนตาซีระดับสูงที่เดินเรื่องตามชาวไร่หนุ่มคนหนึ่งและเพื่อนร่วมทางขณะที่พวกเขาออกเดินทางเพื่อกำจัดกองกำลังที่รุกราน ในตอนแรก กลุ่มตัวเอกเพียงต้องการเตือนเมืองใกล้เคียงเกี่ยวกับการรุกรานของเผ่าพันธุ์สิ่งมีชีวิตที่ชื่อครุก และในอีกไม่นาน ชาวไร่คนดังกล่าวและเพื่อนร่วมทางกับเขาตกอยู่ในสถานการณ์หาทางเอาชนะเผ่าพันธุ์อื่นที่เรียกว่าเซกอย่างหลีกเลี่ยงไม่ได้ ซึ่งฟื้นคืนพลังใหม่หลังจากถูกคุมขังอยู่ 300 ปี โลกของดันเจียนซีจไม่ใช้ระบบเลเวลเหมือนกับวิดีโอเกมเล่นตามบทบาทอื่น ๆ ในยุคนั้น หากแต่เป็นพื้นที่เดียวที่ต่อเนื่อง โดยปราศจากการโหลดหน้าจอ ซึ่งผู้เล่นเดินทางผ่านเพื่อต่อสู้กับฝูงศัตรู นอกจากนี้ แทนที่จะกำหนดคลาสตัวละครและควบคุมตัวละครทั้งหมดในกลุ่มด้วยตนเอง ผู้เล่นจะควบคุมกลยุทธ์และอาวุธ ตลอดจนการใช้เวทมนตร์โดยรวมของพวกเขา ซึ่งกำกับการเติบโตของตัวละคร\"\"\"\n",
        "\n",
        "\n",
        "input_ids = tokenizer.encode(\n",
        "    text_to_predict, return_tensors=\"pt\", add_special_tokens=True\n",
        ")\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    num_beams=2,\n",
        "    max_length=1024,\n",
        "    repetition_penalty=1.5,\n",
        "    length_penalty=1.0,\n",
        "    early_stopping=True,\n",
        "    top_p=50,\n",
        "    top_k=0.95,\n",
        "    num_return_sequences=1,\n",
        ")\n",
        "preds = [\n",
        "          tokenizer.decode(\n",
        "                g,\n",
        "                skip_special_tokens=True,\n",
        "                clean_up_tokenization_spaces=True,\n",
        "            )\n",
        "            for g in generated_ids\n",
        "        ]\n",
        "\n",
        "print(preds)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "599dbc988367df75f394341c14191e4f45ca195597a9b0aa004fda5844c2c20f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "mT5_train_thai(10).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a577f4a8a07a45229cb9837d6c0c6bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c43fddadbd6a4e4dafcb5fcd1bd471d4",
              "IPY_MODEL_bd393ef962614479b8b02e9e1b0ad19b",
              "IPY_MODEL_1ce7ffc6310d4954ab722dbb9108041a"
            ],
            "layout": "IPY_MODEL_0369f86bbbd444209bf0956213a98e6d"
          }
        },
        "c43fddadbd6a4e4dafcb5fcd1bd471d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bead2402c09c482bbd483d857700ed65",
            "placeholder": "​",
            "style": "IPY_MODEL_a52eb124976e4faba7d5fb11983fea74",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "bd393ef962614479b8b02e9e1b0ad19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c5641d3422b43288f6c4799e7748e2e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31a460e7eb0f4e1095e61ef2afc0f321",
            "value": 2
          }
        },
        "1ce7ffc6310d4954ab722dbb9108041a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7497e6bf01664ea79d5586eaa73daad6",
            "placeholder": "​",
            "style": "IPY_MODEL_af47413154ea47aa8f2af208b4cf6121",
            "value": " 2/2 [00:00&lt;00:00,  4.23it/s]"
          }
        },
        "0369f86bbbd444209bf0956213a98e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "bead2402c09c482bbd483d857700ed65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a52eb124976e4faba7d5fb11983fea74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c5641d3422b43288f6c4799e7748e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31a460e7eb0f4e1095e61ef2afc0f321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7497e6bf01664ea79d5586eaa73daad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af47413154ea47aa8f2af208b4cf6121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d544e76a3fbc4e71a007139298c55f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1b5cc8a67d64cd783a2c9fa11227dc8",
              "IPY_MODEL_c8ac69fca6914b1f8eb0ca9556dc9fc5",
              "IPY_MODEL_7fd3493ebd1747b29c2492371925e20b"
            ],
            "layout": "IPY_MODEL_24a7dc38b673438bb13e471c7d162323"
          }
        },
        "f1b5cc8a67d64cd783a2c9fa11227dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71caa6aabab14199a6f0949ad571644b",
            "placeholder": "​",
            "style": "IPY_MODEL_992e7cc84c274c84ae643ee9e7bbe58b",
            "value": "Epoch 0:  57%"
          }
        },
        "c8ac69fca6914b1f8eb0ca9556dc9fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5114330ee6544202ac54a67c672d4d7f",
            "max": 4041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_600886ca0c2248cdaa9f4d44b7dbd612",
            "value": 2300
          }
        },
        "7fd3493ebd1747b29c2492371925e20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a38c7f18bfe4c299c3ab9a5b8c3a818",
            "placeholder": "​",
            "style": "IPY_MODEL_5475c31a35ba4481a85de75aecc7ee35",
            "value": " 2300/4041 [21:11&lt;16:02,  1.81it/s, loss=0.899, v_num=0, loss_step=0.719]"
          }
        },
        "24a7dc38b673438bb13e471c7d162323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "71caa6aabab14199a6f0949ad571644b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992e7cc84c274c84ae643ee9e7bbe58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5114330ee6544202ac54a67c672d4d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600886ca0c2248cdaa9f4d44b7dbd612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a38c7f18bfe4c299c3ab9a5b8c3a818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5475c31a35ba4481a85de75aecc7ee35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}