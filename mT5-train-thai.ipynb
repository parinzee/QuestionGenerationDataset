{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mt5-thai-QG\n",
    "This is notebook detailing how to finetune **mt5 for question-generation in the Thai language** \n",
    "## Installing Requirements and Clone Git Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ijson in /home/parinzee/anaconda3/lib/python3.9/site-packages (3.1.4)\n",
      "Requirement already satisfied: pandas in /home/parinzee/anaconda3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: torch in /home/parinzee/anaconda3/lib/python3.9/site-packages (1.11.0+cpu)\n",
      "Requirement already satisfied: transformers in /home/parinzee/anaconda3/lib/python3.9/site-packages (4.19.2)\n",
      "Requirement already satisfied: sentencepiece in /home/parinzee/anaconda3/lib/python3.9/site-packages (0.1.96)\n",
      "Requirement already satisfied: protobuf in /home/parinzee/anaconda3/lib/python3.9/site-packages (4.21.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/parinzee/anaconda3/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /home/parinzee/anaconda3/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: requests in /home/parinzee/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: filelock in /home/parinzee/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/parinzee/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Remove \"sample_data\" in colab\n",
    "!rm -rf sample_data\n",
    "# Solve some protobuf problems\n",
    "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION='python'\n",
    "# Install programs\n",
    "%pip install ijson pandas torch transformers sentencepiece protobuf beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather & Process datasets\n",
    "- xquad-thai\n",
    "- iapp-wiki-qa-dataset\n",
    "- thaiqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'detail' (Error on 'detail' is expected because of the dataset structure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>สร้าง 5 คำถาม: ชื่อสินค้า กระจก Washi Haruki W...</td>\n",
       "      <td>1. ขอทราบชื่อสินค้าหน่อย A: กระจก Washi Haruki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>สร้าง 4 คำถาม: ภาษาโปรแกรม คือภาษาประดิษฐ์ชนิด...</td>\n",
       "      <td>1. ภาษาโปรแกรมคืออะไร A: ภาษาประดิษฐ์ชนิดหนึ่ง...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>สร้าง 5 คำถาม: แม่น้ำลิมโปโป (อังกฤษ: Limpopo ...</td>\n",
       "      <td>1. แม่น้ำลิมโปโป เป็นแม่น้ำในทวีปอะไร A: ทวีปแ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>สร้าง 1 คำถาม: อะกลีอา (อังกฤษ: Aglaea) หรือ อ...</td>\n",
       "      <td>1. อะกลีอาคือใคร A: เทพีองค์เล็กที่สุดในสามองค...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>สร้าง 2 คำถาม: หวง เสี่ยวหมิง หวง เสี่ยวหมิง (...</td>\n",
       "      <td>1. หวง เสี่ยวหมิง เป็นนักแสดงและนักร้องชาวจีนท...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>สร้าง 4 คำถาม: เดทเมทัล (อังกฤษ: Death metal) ...</td>\n",
       "      <td>1. เดทเมทัลคืออะไร A: แนวเพลงย่อยของเอกซ์ตรีมเ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>สร้าง 2 คำถาม: ภัสสร บุณยเกียรติ ภัสสร เหลียวร...</td>\n",
       "      <td>1. ภัสสร บุณยเกียรติได้รับรางวัลใดจากการประกวด...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>สร้าง 2 คำถาม: การเต้นแท็ป การเต้นแท็ป หรือ แท...</td>\n",
       "      <td>1. การเต้นแท็ปมีต้นกำเนิดมาจากประเทศอะไร A: สห...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>สร้าง 3 คำถาม: โรเบิร์ต ไมเคิล \"ร็อบ\" ชไนเดอร์...</td>\n",
       "      <td>1. ร็อบ ชไนเดอร์ เกิดเมื่อวันที่เท่าไร A: เกิด...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>สร้าง 5 คำถาม: แอนดรูว์ เจมส์ ฮอย, โอเอเอ็ม[5]...</td>\n",
       "      <td>1. แอนดรูว์ ฮอยคือใคร A: นักกีฬาขี่ม้าระดับโอล...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            source_text  \\\n",
       "1725  สร้าง 5 คำถาม: ชื่อสินค้า กระจก Washi Haruki W...   \n",
       "1570  สร้าง 4 คำถาม: ภาษาโปรแกรม คือภาษาประดิษฐ์ชนิด...   \n",
       "1483  สร้าง 5 คำถาม: แม่น้ำลิมโปโป (อังกฤษ: Limpopo ...   \n",
       "680   สร้าง 1 คำถาม: อะกลีอา (อังกฤษ: Aglaea) หรือ อ...   \n",
       "2495  สร้าง 2 คำถาม: หวง เสี่ยวหมิง หวง เสี่ยวหมิง (...   \n",
       "...                                                 ...   \n",
       "1009  สร้าง 4 คำถาม: เดทเมทัล (อังกฤษ: Death metal) ...   \n",
       "2649  สร้าง 2 คำถาม: ภัสสร บุณยเกียรติ ภัสสร เหลียวร...   \n",
       "3198  สร้าง 2 คำถาม: การเต้นแท็ป การเต้นแท็ป หรือ แท...   \n",
       "1048  สร้าง 3 คำถาม: โรเบิร์ต ไมเคิล \"ร็อบ\" ชไนเดอร์...   \n",
       "2085  สร้าง 5 คำถาม: แอนดรูว์ เจมส์ ฮอย, โอเอเอ็ม[5]...   \n",
       "\n",
       "                                            target_text  \n",
       "1725  1. ขอทราบชื่อสินค้าหน่อย A: กระจก Washi Haruki...  \n",
       "1570  1. ภาษาโปรแกรมคืออะไร A: ภาษาประดิษฐ์ชนิดหนึ่ง...  \n",
       "1483  1. แม่น้ำลิมโปโป เป็นแม่น้ำในทวีปอะไร A: ทวีปแ...  \n",
       "680   1. อะกลีอาคือใคร A: เทพีองค์เล็กที่สุดในสามองค...  \n",
       "2495  1. หวง เสี่ยวหมิง เป็นนักแสดงและนักร้องชาวจีนท...  \n",
       "...                                                 ...  \n",
       "1009  1. เดทเมทัลคืออะไร A: แนวเพลงย่อยของเอกซ์ตรีมเ...  \n",
       "2649  1. ภัสสร บุณยเกียรติได้รับรางวัลใดจากการประกวด...  \n",
       "3198  1. การเต้นแท็ปมีต้นกำเนิดมาจากประเทศอะไร A: สห...  \n",
       "1048  1. ร็อบ ชไนเดอร์ เกิดเมื่อวันที่เท่าไร A: เกิด...  \n",
       "2085  1. แอนดรูว์ ฮอยคือใคร A: นักกีฬาขี่ม้าระดับโอล...  \n",
       "\n",
       "[3816 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "import ijson\n",
    "import json\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def download_dataset(url, file_name):\n",
    "    urllib.request.urlretrieve(\n",
    "        url,\n",
    "        os.path.join(\"dataset/\", file_name),\n",
    "        reporthook=(\n",
    "            lambda count, block, total: print(\n",
    "                f\"Downloading {file_name}: {math.floor((count * block) / total * 100)}%\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    print(f\"Downloaded {file_name} from {url}\")\n",
    "\n",
    "\n",
    "# Check if the dataset already exists\n",
    "if not (os.path.exists(\"dataset/xquad.json\") and os.path.exists(\"dataset/iapp-thai-wikipedia-qa.json\")):\n",
    "\n",
    "    # Download all datasets\n",
    "    download_dataset(\"https://github.com/deepmind/xquad/raw/master/xquad.th.json\", \"xquad.json\")\n",
    "    download_dataset(\"https://raw.githubusercontent.com/iapp-technology/iapp-wiki-qa-dataset/main/iapp-thai-wikipedia-qa-1961-docs-9170-questions.json\", \"iapp-thai-wikipedia-qa.json\")\n",
    "    download_dataset(\"https://github.com/PyThaiNLP/thaiqa_squad/raw/main/data.zip\", \"thaiqa.zip\")\n",
    "    with ZipFile(\"dataset/thaiqa.zip\") as zipfile:\n",
    "        os.mkdir(\"dataset/thaiqa\")\n",
    "        zipfile.extractall(\"dataset/thaiqa/\")\n",
    "\n",
    "# This list will store all the Q&A\n",
    "source_list = []\n",
    "target_list = []\n",
    "\n",
    "# Start cleaning data\n",
    "squad = open(os.path.join(\"dataset/\", \"xquad.json\"))\n",
    "iapp = open(os.path.join(\"dataset/\", \"iapp-thai-wikipedia-qa.json\"))\n",
    "iapp_keys = open(os.path.join(\"dataset/\", \"iapp-thai-wikipedia-qa.json\"))\n",
    "thaiqa = open(os.path.join(\"dataset/thaiqa/data/train.jsonl\"))\n",
    "\n",
    "squad_json = ijson.items(squad, \"data.item\")\n",
    "iapp_json = json.load(iapp)\n",
    "iapp_keys = ijson.kvitems(iapp_keys, \"db\")\n",
    "thaiqa_df = pd.read_json(thaiqa, lines=True)\n",
    "\n",
    "# Get data from xquad\n",
    "for obj in squad_json:\n",
    "    paragraphs = obj[\"paragraphs\"]\n",
    "    for p in paragraphs:\n",
    "        context = p[\"context\"]\n",
    "        qas = [p for p in p[\"qas\"] if len(p) > 0]\n",
    "\n",
    "        source_text = f\"สร้าง {len(qas)} คำถาม: {context}\"\n",
    "        target_text = \"\"\n",
    "\n",
    "        for number, qa in enumerate(qas):\n",
    "            target_text += (\n",
    "                f\"{number + 1}. {qa['question']} A: {qa['answers'][0]['text']} \"\n",
    "            )\n",
    "\n",
    "        source_list.append(source_text.strip())\n",
    "        target_list.append(target_text.strip())\n",
    "\n",
    "# Get dataset from iapp\n",
    "for key in iapp_keys:\n",
    "    try:\n",
    "        obj = iapp_json[\"db\"][key[0]] \n",
    "        context = obj[\"detail\"]\n",
    "        qas = obj[\"QA\"]\n",
    "        target_text = \"\"\n",
    "\n",
    "        qa_amount = 0\n",
    "\n",
    "        for number, qa in enumerate(qas):\n",
    "            if len(qa[\"a\"]) != 0 and len(qa[\"q\"]) != 0:\n",
    "                target_text += (\n",
    "                    f\"{number + 1}. {qa['q']} A: {qa['a'][0]} \"\n",
    "                )\n",
    "                qa_amount += 1\n",
    "\n",
    "        source_text = f\"สร้าง {qa_amount} คำถาม: {context}\"\n",
    "        source_list.append(source_text.strip())\n",
    "        target_list.append(target_text.strip())\n",
    "    \n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e} (Error on 'detail' is expected because of the dataset structure\")\n",
    "    \n",
    "# Get data from thaiqa\n",
    "article_ids = set(thaiqa_df[\"article_id\"])\n",
    "for id in article_ids:\n",
    "    questions = thaiqa_df[thaiqa_df[\"article_id\"] == id]\n",
    "\n",
    "    # Remove html markup\n",
    "    soup = BeautifulSoup(questions[\"context\"].iloc[0])\n",
    "\n",
    "    # Remove parenthesis because some are empty\n",
    "    context = re.sub(r'\\(\\)', '', soup.text)\n",
    "\n",
    "    # Remove double spaces resulting from removing parenthesis\n",
    "    context = re.sub(r'\\s\\s+', \" \", context)\n",
    "\n",
    "    source_text = f\"สร้าง {len(questions)} คำถาม: {context}\"\n",
    "    target_text = \"\"\n",
    "\n",
    "    qa_number = 1\n",
    "    for _, question in questions.iterrows():\n",
    "        target_text += f\"{qa_number}. {question['question']} A: {question['answer']} \"\n",
    "        qa_number += 1\n",
    "    \n",
    "    source_list.append(source_text.strip())\n",
    "    target_list.append(target_text.strip())\n",
    "\n",
    "dataframe = pd.DataFrame({\"source_text\": source_list, \"target_text\": target_list})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parinzee/anaconda3/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    MT5ForConditionalGeneration,\n",
    "    MT5TokenizerFast,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")\n",
    "tokenizer = MT5TokenizerFast.from_pretrained(\"google/mt5-small\")\n",
    "collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
    "\n",
    "tokenized_data = []\n",
    "\n",
    "# Apply tokenizer\n",
    "for _, row in dataframe.iterrows():\n",
    "    source = row[\"source_text\"]\n",
    "    target = row[\"target_text\"]\n",
    "    max_length = 2048\n",
    "\n",
    "    source_encoding = tokenizer(\n",
    "        source,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_special_tokens_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    target_encoding = tokenizer(\n",
    "        target,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_special_tokens_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    tokenized_data.append(\n",
    "        dict(\n",
    "            input_ids=source_encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=source_encoding[\"attention_mask\"].flatten(),\n",
    "            labels=target_encoding[\"input_ids\"].flatten(),\n",
    "            labels_attention_mask=target_encoding[\"attention_mask\"].flatten(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "tokenized_data = np.array(tokenized_data)\n",
    "train, test = tokenized_data[:80,:], tokenized_data[80:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3592,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "tokenized_data = np.array(tokenized_data)\n",
    "index_to_split = math.floor(tokenized_data.shape[0] * 0.8)\n",
    "train, test = tokenized_data[:index_to_split], tokenized_data[index_to_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"outputs\", evaluation_strategy=\"epoch\")\n",
    "trainer = Trainer(model=model, args=TrainingArguments, data_collator=collator)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplet5 import SimpleT5\n",
    "\n",
    "model = SimpleT5()\n",
    "model.from_pretrained(model_type=\"mt5\", model_name=\"google/mt5-small\")\n",
    "\n",
    "model.train(train_df=train_df,\n",
    "          eval_df=test_df, \n",
    "          source_max_token_len=1024, \n",
    "          target_max_token_len=1024, \n",
    "          batch_size=1, max_epochs=20, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the trained model for inferencing:\n",
    "model.load_model(\"mt5\",\"\", use_gpu=True)\n",
    "\n",
    "text_to_summarize=\"\"\"สร้าง 3 คำถาม: ดันเจียนซีจ (อังกฤษ: Dungeon Siege) เป็นเกมแอ็กชันเล่นตามบทบาทที่พัฒนาโดยแก๊สเพาเวิร์ดเกมส์ ซึ่งไมโครซอฟท์ได้จัดจำหน่ายบนแพลตฟอร์มไมโครซอฟท์ วินโดวส์ ในเดือนเมษายน ค.ศ. 2002 และเดสทิเนียร์ได้จัดจำหน่ายบนแพลตฟอร์มแมคโอเอสเท็นในปีถัดไป โดยมีฉากอยู่ในอาณาจักรยุคกลางสมมติ ชื่อ เอห์บ เกมนี้ยังจัดเป็นแนวแฟนตาซีระดับสูงที่เดินเรื่องตามชาวไร่หนุ่มคนหนึ่งและเพื่อนร่วมทางขณะที่พวกเขาออกเดินทางเพื่อกำจัดกองกำลังที่รุกราน ในตอนแรก กลุ่มตัวเอกเพียงต้องการเตือนเมืองใกล้เคียงเกี่ยวกับการรุกรานของเผ่าพันธุ์สิ่งมีชีวิตที่ชื่อครุก และในอีกไม่นาน ชาวไร่คนดังกล่าวและเพื่อนร่วมทางกับเขาตกอยู่ในสถานการณ์หาทางเอาชนะเผ่าพันธุ์อื่นที่เรียกว่าเซกอย่างหลีกเลี่ยงไม่ได้ ซึ่งฟื้นคืนพลังใหม่หลังจากถูกคุมขังอยู่ 300 ปี โลกของดันเจียนซีจไม่ใช้ระบบเลเวลเหมือนกับวิดีโอเกมเล่นตามบทบาทอื่น ๆ ในยุคนั้น หากแต่เป็นพื้นที่เดียวที่ต่อเนื่อง โดยปราศจากการโหลดหน้าจอ ซึ่งผู้เล่นเดินทางผ่านเพื่อต่อสู้กับฝูงศัตรู นอกจากนี้ แทนที่จะกำหนดคลาสตัวละครและควบคุมตัวละครทั้งหมดในกลุ่มด้วยตนเอง ผู้เล่นจะควบคุมกลยุทธ์และอาวุธ ตลอดจนการใช้เวทมนตร์โดยรวมของพวกเขา ซึ่งกำกับการเติบโตของตัวละคร\n",
    "\"\"\"\n",
    "\n",
    "print(model.predict(text_to_summarize, max_length=1024)[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "599dbc988367df75f394341c14191e4f45ca195597a9b0aa004fda5844c2c20f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
