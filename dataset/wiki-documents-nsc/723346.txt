<doc id="723346" url="https://th.wikipedia.org/wiki?curid=723346" title="การเรียนรู้เชิงลึก">การเรียนรู้เชิงลึก การเรียนรู้เชิงลึก () เป็นสาขาของการเรียนรู้ของเครื่อง พื้นฐานของการเรียนรู้เชิงลึกคือ อัลกอริทึมที่พยายามจะสร้างแบบจำลองเพื่อแทนความหมายของข้อมูลในระดับสูงโดยการสร้างสถาปัตยกรรมข้อมูลขึ้นมาที่ประกอบไปด้วยโครงสร้างย่อยๆหลายอัน และแต่ละอันนั้นได้มาจากการแปลงที่ไม่เป็นเชิงเส้น การเรียนรู้เชิงลึก อาจมองได้ว่าเป็นวิธีการหนึ่งของการเรียนรู้ของเครื่องที่พยายามเรียนรู้วิธีการแทนข้อมูลอย่างมีประสิทธิภาพ ตัวอย่างเช่น รูปภาพภาพหนึ่ง สามารถแทนได้เป็นเวกเตอร์ของความสว่างต่อจุดพิกเซล หรือมองในระดับสูงขึ้นเป็นเซ็ตของขอบของวัตถุต่างๆ หรือมองว่าเป็นพื้นที่ของรูปร่างใดๆก็ได้ การแทนความหมายดังกล่าวจะทำให้การเรียนรู้ที่จะทำงานต่างๆทำได้ง่ายขึ้น ไม่ว่าจะเป็นการรู้จำใบหน้าหรือการรู้จำการแสดงออกทางสีหน้า การเรียนรู้เชิงลึกถือว่าเป็นวิธีการที่มีศักยภาพสูงในการจัดการกับฟีเจอร์สำหรับการเรียนรู้แบบไม่มีผู้สอนหรือการเรียนรู้แบบกึ่งมีผู้สอน นักวิจัยในสาขานี้พยายามจะหาวิธีการที่ดีขึ้นในการแทนข้อมูลแล้วสร้างแบบจำลองเพื่อเรียนรู้จากตัวแทนของข้อมูลเหล่านี้ในระดับใหญ่ บางวิธีการก็ได้แรงบันดาลใจมาจากสาขาประสาทวิทยาขั้นสูง โดยเฉพาะเรื่องกระบวนการตีความหมายในกระบวนการประมวลผลข้อมูลในสมอง ตัวอย่างของกระบวนการที่การเรียนรู้เชิงลึกนำไปใช้ได้แก่ การเข้ารหัสประสาท อันเป็นกระบวนการหาความสัมพันธ์ระหว่างตัวกระตุ้นกับการตอบสนองของเซลล์ประสาทในสมอง นักวิจัยด้านการเรียนรู้ของเครื่องได้เสนอสถาปัตยกรรมการเรียนรู้หลายแบบบนหลักการของการเรียนรู้เชิงลึกนี้ ได้แก่ โครงข่ายประสาทเทียมแบบลึก (Deep Artificial Neural Networks) โครงข่ายประสาทเทียมแบบสังวัตนาการ (Convolutional Neural Networks) โครงข่ายความเชื่อแบบลึก (Deep Belief Networks) และโครงข่ายประสาทเทียมแบบวนซ้ำ (Recurrent Neural Network) ซึ่งมีการนำมาใช้งานอย่างแพร่หลายในทางคอมพิวเตอร์วิทัศน์ การรู้จำเสียงพูด การประมวลผลภาษาธรรมชาติ การรู้จำเสียง และชีวสารสนเทศศาสตร์นิยาม นิยาม. การเรียนรู้เชิงลึก เป็นสาขาของการเรียนรู้ของเครื่องที่- ประกอบไปด้วยชั้นของหน่วยประมวลผลแบบไม่เป็นเชิงเส้นหลายๆชั้น ข้อมูลขาออกของแต่ละชั้นก่อนหน้าจะเป็นข้อมูลขาเข้าของชั้นต่อไป - มาพื้นฐานมาจากการเรียนรู้ฟีเจอร์หลายๆชั้นหรือการแทนข้อมูลแบบหลายๆชั้น (แบบไม่มีผู้สอน) กล่าวคือ ฟีเจอร์ในชั้นสูงๆจะได้มาจากฟีเจอร์ในชั้นที่ต่ำกว่า เพื่อสร้างมาเป็นการแทนข้อมูลแบบหลายๆชั้น - เป็นส่วนหนึ่งของสาขาการเรียนรู้ของเครื่องในการเรียนรู้การแทนข้อมูล กล่าวคือ การเรียนรู้เชิงลึกประกอบไปด้วย (1) หน่วยประมวลผลแบบไม่เป็นเชิงเส้นหลายๆชั้น (2) แต่ละชั้น จะเรียนรู้การแทนฟีเจอร์ อาจจะเป็นแบบมีผู้สอนหรือไม่มีผู้สอนก็ได้ ทั้งนี้ โครงสร้างในแต่ละชั้นของการเรียนรู้เชิงลึกจะขึ้นอยู่กับปัญหาที่ต้องการจะแก้ไข อาจจะเป็น hidden layer ของโครงข่ายประสาทเทียม หรือหน่วยประมวลผลตรรกะที่ซับซ้อนก็ได้ หรืออาจจะเป็นโนดใน deep generative model อย่างเช่น โครงข่ายความเชื่อแบบลึก (Deep Belief Networks) หรือเครื่องจักรโบลทซ์มันน์เชิงลึก (Deep Boltzmann Machines) ก็ได้แนวคิดพื้นฐาน แนวคิดพื้นฐาน. หลักการโดยทั่วไปของการเรียนรู้เชิงลึกคือการมีหน่วยประมวลผลหลายๆชั้น ข้อมูลขาเข้าในแต่ละชั้นได้มาจากปฏิสัมพันธ์กับชั้นอื่นๆ ทั้งนี้ การเรียนรู้เชิงลึกพยายามหาความสัมพันธ์ที่ล้ำลึกมากขึ้น นั่นคือ เมื่อมีจำนวนของชั้นและหน่วยประมวลผลที่อยู่ในชั้นมากขึ้น ข้อมูลในชั้นสูงๆก็จะยิ่งล้ำลึกซับซ้อน (abstract) มากขึ้น สถาปัตยกรรมโครงสร้างของการเรียนรู้เชิงลึกมักจะสร้างแบบเป็นชั้นๆ (layer-by-layer) ไปด้วยวิธี greedy method ซึ่งการหาสิ่งที่ล้ำลึกซับซ้อนมากขึ้นไปเรื่อยๆในแต่ละชั้นนี้เองที่ทำให้การเรียนรู้เชิงลึกมีประสิทธิภาพมากกว่าวิธีการอื่นๆ ตัวอย่างเช่น ข้อมูลในชั้นต้นๆอาจจะเรียนรู้ว่าภาพที่เข้ามาประกอบด้วยเส้นต่างๆ ชั้นที่สูงไปนำเส้นต่างๆมาประกอบกันเป็นรูปสี่เหลี่ยม และชั้นต่อๆมาคือการหาความสัมพันธ์ของเส้นสี่เหลี่ยมจนกระทั่งคอมพิวเตอร์รู้ได้ว่าภาพที่เข้ามาเป็นภาพของธงชาติ เป็นต้น ในการเรียนรู้แบบมีผู้สอนนั้น การเรียนรู้เชิงลึกจะช่วยลดภาระในการหาฟีเจอร์ที่เกี่ยวข้อง เพราะวิธีการนี้จะแปลงข้อมูลไปสู่รูปแบบอื่นในระดับที่สูงขึ้นโดยอัตโนมัติ และให้ความสำคัญกับข้อมูลที่ซ้ำซ้อนลดลงไปด้วย นอกจากนี้ ยังสามารถนำไปปรับใช้กับการเรียนรู้แบบไม่มีผู้สอนได้ด้วยการตีความ การตีความ. เราอาจจะตีความการเรียนรู้เชิงลึกได้ 2 แนวทางคือ ใช้ทฤษฎีประมาณค่าสากล (universal approximation theorem) และใช้การอนุมานด้วยความน่าจะเป็น (probabilistic inference) ทฤษฎีประมาณค่าสากล สนใจความสามารถของโครงข่ายประสาทแบบป้อนไปข้างหน้า (feedforward neural networks) ที่มี hidden layer เพียงชั้นเดียวและมีขนาดจำกัด เพื่อประมาณค่าของฟังก์ชันต่อเนื่อง โดย George Cybenko ได้พิสูจน์การเรียนรู้เชิงลึกด้วยทฤษฎีนี้ โดยใช้ฟังก์ชันซิกมอยด์ในปี 1989 และต่อมา Hornik นำไปพิสูจน์ต่อสำหรับ feedforward neural networks ที่มีหลายๆชั้น ในปี 1991 ส่วนการตีความด้วยหลักความน่าจะเป็นนั้น มีแนวคิดมาจากการเรียนรู้ของเครื่อง เสนอขึ้นครั้งแรกโดยเจฟฟรีย์ ฮินตัน โยชัว เบนโจ ยานน์ เลอคุน และเยอร์เกน ชมิดฮูเบอร์ นักวิทยาศาสตร์ผู้บุกเบิกสาขาการเรียนรู้เชิงลึกยุคใหม่ แนวคิดนี้จะเน้นการปรับโครงสร้างการเรียนรู้เชิงลึกด้วยการหาโมเดลค่าที่ดีที่สุด (optimization) ที่ดีทั้งสำหรับข้อมูลการสอน (training) และข้อมูลการทดสอบ (testing) ทั้งนี้ การอนุมานด้วยความน่าจะเป็นนั้นจะมองว่า activation nonlinearity นั้นเป็นฟังก์ชันการกระจายแบบสะสม (Cumulative distribution function) ทำให้เกิดเทคนิคการใช้ dropout เป็นตัวควบคุม (regularizer) สำหรับโครงข่ายประสาทเทียม</doc>
