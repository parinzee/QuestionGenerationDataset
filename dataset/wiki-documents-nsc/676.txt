<doc id="676" url="https://th.wikipedia.org/wiki?curid=676" title="ทฤษฎีสารสนเทศ">ทฤษฎีสารสนเทศ ทฤษฎีสารสนเทศ () เป็นสาขาหนึ่งใน ทฤษฎีความน่าจะเป็น และคณิตศาสตร์เชิงสถิติ ขอบข่ายเนื้อหาของทฤษฎีนี้จะเกี่ยวข้องกับสารสนเทศ, เอนโทรปีของสารสนเทศ, ระบบการสื่อสาร, การส่งข้อมูล, ทฤษฎีอัตราการบิดเบือน, วิทยาการเข้ารหัสลับ, สัดส่วนสัญญาณต่อสัญญาณรบกวน, การบีบอัดข้อมูล, การแก้ความผิดพลาด และหัวข้ออื่น ๆ ที่เกี่ยวข้อง คำแปลที่ตามราชบัณฑิต คือ "ทฤษฎีสารสนเทศ" นี้ มาจากคำว่า "information theory" ซึ่งคำว่า information เป็นคำเดียวกันกับที่หมายถึง สารสนเทศ แต่เนื่องจากความหมายของ information theory นั้นจะเกี่ยวเนื่องกับ เนื้อความในแง่ของสัญญาณ จึงอาจจะใช้คำว่า ทฤษฎีข้อมูล แทนความหมายของสารสนเทศ ที่เป็นในแง่ของเนื้อหาข่าวสาร และ สื่อตัวกลาง หรือสื่อบันทึกในบางกรณี ตัวอย่างของการนำทฤษฎีสารสนเทศมาประยุกต์ใช้ ได้แก่ ZIP Files, เครื่องเล่นเอ็มพีสาม , อินเทอร์เน็ตความเร็วสูงดีเอสแอล, อุปกรณ์สื่อสารไร้สาย อาทิ โทรศัพท์มือถือ วิทยุสื่อสาร, เครื่องเล่นซีดี และการศึกษาเกี่ยวกับหลุมดำ เป็นต้นประวัติ ประวัติ. คลาวด์ อี. แชนนอน ได้รับการขนานนามว่าเป็น "บิดาแห่งทฤษฎีสารสนเทศ" ทฤษฎีของแชนนอนนี้ เป็นทฤษฎีแรกที่ได้ทำการวินิจฉัยปัญหาทางการสื่อสาร ในรูปของปัญหาคณิตศาสตร์เชิงสถิติ เป็นทฤษฎีที่ได้เปิดหนทาง ให้วิศวกรการสื่อสาร สามารถคำนวณขนาด หรือปริมาณสูงสุดของช่องสัญญาณ ออกมาในหน่วยบิต (bits) ทฤษฎีสารสนเทศที่เรารู้จักอยู่ในทุกวันนี้ เป็นที่ยอมรับโดยทั่วไปว่า เริ่มต้นจากผลงานตีพิมพ์ของแชนนอนเรื่องทฤษฎีเชิงคณิตศาสตร์ของการสื่อสาร (The Mathematical Theory of Communication) ลงในวารสารทางเทคนิคเบลล์ซิสเต็ม (Bell System Technical Journal) ฉบับเดือนมิถุนายน ในปี พ.ศ. 2491 (ค.ศ. 1948) ซึ่งงานชิ้นนี้นั้น เป็นงานที่ได้สร้างเสริมต่อมาจาก ผลงานของ แฮร์รี นายควิสท์ () และ ราล์ฟ ฮาร์ทลีย์ () ในงานของแชนนอน ที่ทำให้วิศวกรระบบสื่อสาร สามารถออกแบบระบบสื่อสารที่มีประสิทธิภาพสูงขึ้นได้นั้น แชนนอนได้นิยามเอนโทรปีของสารสนเทศเท่ากับ formula_1 สูตรนี้เมื่อนำไปใช้กับ แหล่งกำเนิดสารสนเทศ จะทำให้สามารถคำนวณขนาดของช่องสัญญาณ ที่จำเป็นต้องใช้ในการส่งข้อมูลนั้น ในรูปของรหัสฐานสองได้ โดยถ้าลอการิทึมในสมการข้างต้น เป็นฐานสอง เอนโทรปีที่วัดจะอยู่ในหน่วยบิตเช่นกัน แต่ถ้าเป็น ลอการิทึมฐานธรรมชาติ หรือ ฐาน formula_2 เอนโทรปีที่วัดจะอยู่ในหน่วย แนท (nats) [1] การวัดเอนโทรปีของแชนนอน เป็นการวัดขนาดของสารสนเทศซึ่งอยู่ในข้อความ เมื่อไม่นานมานี้ ได้ปรากฏหลักฐานว่า เอนโทรปี นั้นได้ถูกค้นพบและนิยามในช่วงสงครามโลกครั้งที่สอง โดยแอลัน ทัวริง ที่ เบล็ทชลีย์ พาร์ค () ทัวริง ได้ตั้งชื่อปริมาณนี้ว่าน้ำหนักของหลักฐาน (weight of evidence) และใช้หน่วยวัดเป็น bans และ decibans (อย่าสับสนคำ "weight of evidence" นี้กับคำเดียวกันที่ใช้ในบทความทางด้านการอนุมานทางสถิติ หรือ บัญญัติขึ้นโดย กู๊ด () ซึ่งมีความหมายตรงกับคำที่ทัวริงใช้คือ "log-odds" หรือ "lods") ถึงแม้ว่า ทัวริง และ แชนนอน นั้นได้ทำงานร่วมกันในช่วงสงครามแต่ดูเหมือนว่าทั้งคู่นั้นต่างคนต่างพัฒนาแนวความคิดนี้ขึ้นมาด้วยตนเอง (สำหรับเอกสารอ้างอิงดู Alan Turing: The Enigma โดย แอนดรูว์ ฮอดจส์ Andrew Hodges)ความสัมพันธ์กับเอนโทรปีของอุณหพลศาสตร์ ความสัมพันธ์กับเอนโทรปีของอุณหพลศาสตร์. เอนโทรปีของสารสนเทศ ที่พัฒนาต่อมาจากแนวความคิดดั้งเดิมของ แชนนอน นั้นมีความสัมพันธ์อย่างใกล้ชิดกับ เอนโทรปี ของ อุณหพลศาสตร์ ลุดวิก โบลทซ์แมน ( และ วิลลาร์ด กิบส์ () นั้นมีส่วนสำคัญในการพัฒนาทางด้าน อุณหพลศาสตร์เชิงสถิติ () งานของเขานั้นเกิดจากความพยายามในการที่จะนำคำ เอนโทรปี จาก ทฤษฎีสารสนเทศมาใช้ เอนโทรปี จากแนวความคิดของ ทฤษฎีสารสนเทศ และ แนวความคิดของ อุณหพลศาสตร์เชิงสถิติ นี้มีความสัมพันธ์กันที่ลึกซึ้ง ตัวอย่างหนึ่งที่ใช้แสดงความสัมพันธ์ระหว่าง สารสนเทศ และ เอนโทรปีของอุณหพลศาสตร์ คือ ปีศาจของแมกซ์เวลล์ () ซึ่งเป็นปิศาจเฝ้าตูดควบคุมการเลือกผ่านของโมเลกุล เพื่อสร้างการไหลของพลังงานสวนทางกับเอนโทรปีของอุณหพลศาสตร์ ในการแหกกฎข้อที่สองของอุณหพลศาสตร์ แต่ในขณะเดียวกัน ในการคุมตูดนั้นปีศาจก็ต้องการข้อมูล ที่แม่นยำ ซึ่งทั้งสองนี้หักล้างกันไปทำให้ปิศาจไม่สามารถสร้างความได้เปรียบทางอุณหพลศาสตร์สวนกฎข้อที่สองได้ ปริมาณที่ใช้วัดข้อมูลที่มีประโยชน์ อีกปริมาณหนึ่งก็คือ สารสนเทศร่วม () ซึ่งเป็นปริมาณที่บ่งบอกถึงความขึ้นแก่กันทางสถิติของตัวแปรสุ่มสองตัว นิยามของสารสนเทศที่เกิดร่วมกันของเหตุการณ์ formula_3 และ formula_4 คือ โดยที่ formula_6 คือ เอนโทรปีร่วม นิยามโดย และ formula_8 คือ เอนโทรปีตามเงื่อนไข () ของ formula_3 มีเงื่อนไขขึ้นกับค่าสังเกตการณ์ของ formula_4 ดังนั้น สารสนเทศร่วม สามารถตีความ หมายถึง ปริมาณของความไม่แน่นอนของค่า formula_3 ที่ลดลงเมื่อรู้ค่าที่แน่นอนของ formula_4 และในทางกลับกัน</doc>
