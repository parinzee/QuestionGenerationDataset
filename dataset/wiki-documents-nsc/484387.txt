<doc id="484387" url="https://th.wikipedia.org/wiki?curid=484387" title="ข้อมูลขนาดใหญ่">ข้อมูลขนาดใหญ่ ในสาขาเทคโนโลยีสารสนเทศ, ข้อมูลขนาดใหญ่ () คือชุมนุมของชุดข้อมูลที่มีขนาดและความซับซ้อนมาก จนมันยากที่จะประมวลผลได้ด้วยเครื่องมือจัดการฐานข้อมูลที่มีอยู่ ความท้าทายนี้รวมถึงการจับบันทึก การจัดเก็บ การค้นหา การแบ่งปัน การวิเคราะห์ และการวาดภาพข้อมูล แนวโน้มของชุดข้อมูลต่างๆ ที่ใหญ่ขึ้นเป็นผลจากสารสนเทศเพิ่มเติมที่ได้มาจากการวิเคราะห์ชุดข้อมูลชุดใหญ่ชุดเดียวของข้อมูลที่เกี่ยวข้องกัน เทียบกับชุดข้อมูลย่อยๆ หลายชุดที่แยกจากกันที่มีขนาดรวมกันแล้วเท่ากัน สิ่งนี้อนุญาตให้ความเชื่อมโยงถูกค้นพบได้ เพื่อ "หาแนวโน้มทางธุรกิจ ตัดสินคุณภาพของงานวิจัย ป้องกันโรค วิเคราะห์การอ้างอิงกฎหมาย ต่อสู้กับอาชญากรรม และบอกสภาพการจราจรตามเวลาจริง"นิยาม นิยาม. big data มักรวมถึงชุดข้อมูลที่มีขนาดใหญ่เกินกว่าความสามารถของซอฟต์แวร์ที่ใช้กันอยู่ทั่วไป จะจับบันทึก จัดการ และประมวลผลข้อมูลดังกล่าวได้ภายในเวลาที่ยอมรับได้ ขนาดของ big data นั้นเป็นเป้าหมายที่เคลื่อนไปเรื่อยๆ ตามเวลา ในปี 2012 ขนาดของมันอยู่ที่ตั้งแต่ไม่กี่เทราไบต์ไปจนถึงหลายๆ เพตาไบต์ในชุดข้อมูลชุดเดียว ด้วยความยากลำบากนี้ แพลตฟอร์มใหม่สำหรับ "big data" จึงได้เกิดขึ้นเพื่อจะสามารถทำจัดการกับข้อมูลจำนวนมากเช่นนั้นได้ ตัวอย่างเช่น Apache Hadoop Big Data Platform.ตัวอย่าง ตัวอย่าง. ตัวอย่างของ big data เช่น ปูมบันทึกการใช้งานเว็บ, RFID, เครือข่ายเซ็นเซอร์, เครือข่ายสังคม, ข้อมูลสังคม (social data), เอกสารและข้อความบนอินเทอร์เน็ต, การทำดัชนีค้นหาอินเทอร์เน็ต, บันทึกการโทรศัพท์, ดาราศาสตร์, วิทยาศาสตร์สภาพอากาศ, จีโนมิกส์, การวิจัยทางชีวธรณีเคมี ชีววิทยา และการวิจัยทางวิทยาศาสตร์ที่ซับซ้อนและมักจะข้ามสาขา, การสอดส่องทางการทหาร, เวชระเบียน, คลังภาพถ่าย, คลังภาพเคลื่อนไหว, และพาณิชย์อิเล็กทรอนิกส์ขนาดใหญ่</doc>
